{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0f09fab-01e5-400d-a23f-a840a731c285",
   "metadata": {},
   "source": [
    "# Comprehensive Metabolomics of ME/CFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa8e8817-8871-4769-847e-5245b20173ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "294d975d-66f8-4651-812e-8bc6289c3be5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_0001</th>\n",
       "      <th>sample_0002</th>\n",
       "      <th>sample_0003</th>\n",
       "      <th>sample_0004</th>\n",
       "      <th>sample_0005</th>\n",
       "      <th>sample_0006</th>\n",
       "      <th>sample_0007</th>\n",
       "      <th>sample_0008</th>\n",
       "      <th>sample_0009</th>\n",
       "      <th>sample_0010</th>\n",
       "      <th>...</th>\n",
       "      <th>sample_0043</th>\n",
       "      <th>sample_0044</th>\n",
       "      <th>sample_0045</th>\n",
       "      <th>sample_0046</th>\n",
       "      <th>sample_0047</th>\n",
       "      <th>sample_0048</th>\n",
       "      <th>sample_0049</th>\n",
       "      <th>sample_0050</th>\n",
       "      <th>sample_0051</th>\n",
       "      <th>sample_0052</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compound_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>compound_0001</th>\n",
       "      <td>672039.0</td>\n",
       "      <td>599392.0</td>\n",
       "      <td>1023576.0</td>\n",
       "      <td>804353.0</td>\n",
       "      <td>557954.0</td>\n",
       "      <td>1609237.0</td>\n",
       "      <td>927166.0</td>\n",
       "      <td>1088624.0</td>\n",
       "      <td>707863.0</td>\n",
       "      <td>799685.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1216151.0</td>\n",
       "      <td>662043.0</td>\n",
       "      <td>935385.0</td>\n",
       "      <td>813732.0</td>\n",
       "      <td>576076.0</td>\n",
       "      <td>1014031.0</td>\n",
       "      <td>678012.0</td>\n",
       "      <td>385437.0</td>\n",
       "      <td>1019252.0</td>\n",
       "      <td>434933.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compound_0002</th>\n",
       "      <td>74472.0</td>\n",
       "      <td>23403.0</td>\n",
       "      <td>33924.0</td>\n",
       "      <td>15061.0</td>\n",
       "      <td>40816.0</td>\n",
       "      <td>15061.0</td>\n",
       "      <td>15061.0</td>\n",
       "      <td>26107.0</td>\n",
       "      <td>82198.0</td>\n",
       "      <td>30903.0</td>\n",
       "      <td>...</td>\n",
       "      <td>27049.0</td>\n",
       "      <td>15061.0</td>\n",
       "      <td>62109.0</td>\n",
       "      <td>42156.0</td>\n",
       "      <td>21103.0</td>\n",
       "      <td>43291.0</td>\n",
       "      <td>26561.0</td>\n",
       "      <td>15061.0</td>\n",
       "      <td>72704.0</td>\n",
       "      <td>39783.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compound_0003</th>\n",
       "      <td>54758.0</td>\n",
       "      <td>22374.0</td>\n",
       "      <td>57498.0</td>\n",
       "      <td>21318.0</td>\n",
       "      <td>58013.0</td>\n",
       "      <td>23417.0</td>\n",
       "      <td>21318.0</td>\n",
       "      <td>34094.0</td>\n",
       "      <td>53840.0</td>\n",
       "      <td>24596.0</td>\n",
       "      <td>...</td>\n",
       "      <td>21318.0</td>\n",
       "      <td>23948.0</td>\n",
       "      <td>41830.0</td>\n",
       "      <td>87383.0</td>\n",
       "      <td>26378.0</td>\n",
       "      <td>74266.0</td>\n",
       "      <td>38397.0</td>\n",
       "      <td>21318.0</td>\n",
       "      <td>68930.0</td>\n",
       "      <td>26156.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compound_0004</th>\n",
       "      <td>230130.0</td>\n",
       "      <td>112937.0</td>\n",
       "      <td>256586.0</td>\n",
       "      <td>62260.0</td>\n",
       "      <td>193937.0</td>\n",
       "      <td>53626.0</td>\n",
       "      <td>67179.0</td>\n",
       "      <td>105097.0</td>\n",
       "      <td>152781.0</td>\n",
       "      <td>153281.0</td>\n",
       "      <td>...</td>\n",
       "      <td>118678.0</td>\n",
       "      <td>89233.0</td>\n",
       "      <td>152517.0</td>\n",
       "      <td>74130.0</td>\n",
       "      <td>200452.0</td>\n",
       "      <td>228867.0</td>\n",
       "      <td>113867.0</td>\n",
       "      <td>29731.0</td>\n",
       "      <td>283890.0</td>\n",
       "      <td>90141.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compound_0005</th>\n",
       "      <td>128065.0</td>\n",
       "      <td>66968.0</td>\n",
       "      <td>92744.0</td>\n",
       "      <td>29284.0</td>\n",
       "      <td>100637.0</td>\n",
       "      <td>44635.0</td>\n",
       "      <td>23037.0</td>\n",
       "      <td>93367.0</td>\n",
       "      <td>132301.0</td>\n",
       "      <td>75821.0</td>\n",
       "      <td>...</td>\n",
       "      <td>57250.0</td>\n",
       "      <td>42497.0</td>\n",
       "      <td>113116.0</td>\n",
       "      <td>98979.0</td>\n",
       "      <td>85391.0</td>\n",
       "      <td>132303.0</td>\n",
       "      <td>90500.0</td>\n",
       "      <td>23037.0</td>\n",
       "      <td>132772.0</td>\n",
       "      <td>66803.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               sample_0001  sample_0002  sample_0003  sample_0004  \\\n",
       "compound_id                                                         \n",
       "compound_0001     672039.0     599392.0    1023576.0     804353.0   \n",
       "compound_0002      74472.0      23403.0      33924.0      15061.0   \n",
       "compound_0003      54758.0      22374.0      57498.0      21318.0   \n",
       "compound_0004     230130.0     112937.0     256586.0      62260.0   \n",
       "compound_0005     128065.0      66968.0      92744.0      29284.0   \n",
       "\n",
       "               sample_0005  sample_0006  sample_0007  sample_0008  \\\n",
       "compound_id                                                         \n",
       "compound_0001     557954.0    1609237.0     927166.0    1088624.0   \n",
       "compound_0002      40816.0      15061.0      15061.0      26107.0   \n",
       "compound_0003      58013.0      23417.0      21318.0      34094.0   \n",
       "compound_0004     193937.0      53626.0      67179.0     105097.0   \n",
       "compound_0005     100637.0      44635.0      23037.0      93367.0   \n",
       "\n",
       "               sample_0009  sample_0010  ...  sample_0043  sample_0044  \\\n",
       "compound_id                              ...                             \n",
       "compound_0001     707863.0     799685.0  ...    1216151.0     662043.0   \n",
       "compound_0002      82198.0      30903.0  ...      27049.0      15061.0   \n",
       "compound_0003      53840.0      24596.0  ...      21318.0      23948.0   \n",
       "compound_0004     152781.0     153281.0  ...     118678.0      89233.0   \n",
       "compound_0005     132301.0      75821.0  ...      57250.0      42497.0   \n",
       "\n",
       "               sample_0045  sample_0046  sample_0047  sample_0048  \\\n",
       "compound_id                                                         \n",
       "compound_0001     935385.0     813732.0     576076.0    1014031.0   \n",
       "compound_0002      62109.0      42156.0      21103.0      43291.0   \n",
       "compound_0003      41830.0      87383.0      26378.0      74266.0   \n",
       "compound_0004     152517.0      74130.0     200452.0     228867.0   \n",
       "compound_0005     113116.0      98979.0      85391.0     132303.0   \n",
       "\n",
       "               sample_0049  sample_0050  sample_0051  sample_0052  \n",
       "compound_id                                                        \n",
       "compound_0001     678012.0     385437.0    1019252.0     434933.0  \n",
       "compound_0002      26561.0      15061.0      72704.0      39783.0  \n",
       "compound_0003      38397.0      21318.0      68930.0      26156.0  \n",
       "compound_0004     113867.0      29731.0     283890.0      90141.0  \n",
       "compound_0005      90500.0      23037.0     132772.0      66803.0  \n",
       "\n",
       "[5 rows x 52 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"data_matrix-table 1.csv\", sep=\";\", escapechar = '.', decimal = ',', index_col = 'compound_id')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa0fdec7-7c8a-4a3a-94ae-2e3373492792",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>compound_id</th>\n",
       "      <th>compound_0001</th>\n",
       "      <th>compound_0002</th>\n",
       "      <th>compound_0003</th>\n",
       "      <th>compound_0004</th>\n",
       "      <th>compound_0005</th>\n",
       "      <th>compound_0006</th>\n",
       "      <th>compound_0007</th>\n",
       "      <th>compound_0008</th>\n",
       "      <th>compound_0009</th>\n",
       "      <th>compound_0010</th>\n",
       "      <th>...</th>\n",
       "      <th>compound_1781</th>\n",
       "      <th>compound_1782</th>\n",
       "      <th>compound_1783</th>\n",
       "      <th>compound_1784</th>\n",
       "      <th>compound_1785</th>\n",
       "      <th>compound_1786</th>\n",
       "      <th>compound_1787</th>\n",
       "      <th>compound_1788</th>\n",
       "      <th>compound_1789</th>\n",
       "      <th>compound_1790</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sample_0001</th>\n",
       "      <td>672039.0</td>\n",
       "      <td>74472.0</td>\n",
       "      <td>54758.0</td>\n",
       "      <td>230130.0</td>\n",
       "      <td>128065.0</td>\n",
       "      <td>1595220.0</td>\n",
       "      <td>1563524.0</td>\n",
       "      <td>306946.0</td>\n",
       "      <td>2139132.0</td>\n",
       "      <td>191212.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.2410</td>\n",
       "      <td>2.9821</td>\n",
       "      <td>202.3064</td>\n",
       "      <td>6.3900</td>\n",
       "      <td>9.4495</td>\n",
       "      <td>2368.6685</td>\n",
       "      <td>174.0733</td>\n",
       "      <td>40.5750</td>\n",
       "      <td>484.9198</td>\n",
       "      <td>1771.8030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample_0002</th>\n",
       "      <td>599392.0</td>\n",
       "      <td>23403.0</td>\n",
       "      <td>22374.0</td>\n",
       "      <td>112937.0</td>\n",
       "      <td>66968.0</td>\n",
       "      <td>911738.0</td>\n",
       "      <td>1761776.0</td>\n",
       "      <td>170567.0</td>\n",
       "      <td>1680606.0</td>\n",
       "      <td>245996.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.5322</td>\n",
       "      <td>2.9967</td>\n",
       "      <td>179.9669</td>\n",
       "      <td>5.8186</td>\n",
       "      <td>8.0212</td>\n",
       "      <td>1638.8876</td>\n",
       "      <td>148.6103</td>\n",
       "      <td>27.8358</td>\n",
       "      <td>333.8163</td>\n",
       "      <td>980.4756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample_0003</th>\n",
       "      <td>1023576.0</td>\n",
       "      <td>33924.0</td>\n",
       "      <td>57498.0</td>\n",
       "      <td>256586.0</td>\n",
       "      <td>92744.0</td>\n",
       "      <td>1242042.0</td>\n",
       "      <td>1495843.0</td>\n",
       "      <td>180168.0</td>\n",
       "      <td>1757116.0</td>\n",
       "      <td>208971.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.2848</td>\n",
       "      <td>3.3440</td>\n",
       "      <td>168.2757</td>\n",
       "      <td>5.5424</td>\n",
       "      <td>7.1869</td>\n",
       "      <td>1716.4484</td>\n",
       "      <td>134.0830</td>\n",
       "      <td>28.4095</td>\n",
       "      <td>393.9803</td>\n",
       "      <td>418.6395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample_0004</th>\n",
       "      <td>804353.0</td>\n",
       "      <td>15061.0</td>\n",
       "      <td>21318.0</td>\n",
       "      <td>62260.0</td>\n",
       "      <td>29284.0</td>\n",
       "      <td>1594599.0</td>\n",
       "      <td>1359280.0</td>\n",
       "      <td>219187.0</td>\n",
       "      <td>1655573.0</td>\n",
       "      <td>129250.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.5764</td>\n",
       "      <td>4.3642</td>\n",
       "      <td>184.8738</td>\n",
       "      <td>5.8394</td>\n",
       "      <td>8.1066</td>\n",
       "      <td>1925.0035</td>\n",
       "      <td>152.0123</td>\n",
       "      <td>26.4876</td>\n",
       "      <td>495.5018</td>\n",
       "      <td>738.0438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample_0005</th>\n",
       "      <td>557954.0</td>\n",
       "      <td>40816.0</td>\n",
       "      <td>58013.0</td>\n",
       "      <td>193937.0</td>\n",
       "      <td>100637.0</td>\n",
       "      <td>994207.0</td>\n",
       "      <td>3893889.0</td>\n",
       "      <td>307190.0</td>\n",
       "      <td>1845230.0</td>\n",
       "      <td>116337.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.2900</td>\n",
       "      <td>2.3488</td>\n",
       "      <td>110.1221</td>\n",
       "      <td>4.2770</td>\n",
       "      <td>7.0231</td>\n",
       "      <td>1336.6816</td>\n",
       "      <td>95.3169</td>\n",
       "      <td>16.4406</td>\n",
       "      <td>322.3633</td>\n",
       "      <td>586.9093</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1790 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "compound_id  compound_0001  compound_0002  compound_0003  compound_0004  \\\n",
       "sample_0001       672039.0        74472.0        54758.0       230130.0   \n",
       "sample_0002       599392.0        23403.0        22374.0       112937.0   \n",
       "sample_0003      1023576.0        33924.0        57498.0       256586.0   \n",
       "sample_0004       804353.0        15061.0        21318.0        62260.0   \n",
       "sample_0005       557954.0        40816.0        58013.0       193937.0   \n",
       "\n",
       "compound_id  compound_0005  compound_0006  compound_0007  compound_0008  \\\n",
       "sample_0001       128065.0      1595220.0      1563524.0       306946.0   \n",
       "sample_0002        66968.0       911738.0      1761776.0       170567.0   \n",
       "sample_0003        92744.0      1242042.0      1495843.0       180168.0   \n",
       "sample_0004        29284.0      1594599.0      1359280.0       219187.0   \n",
       "sample_0005       100637.0       994207.0      3893889.0       307190.0   \n",
       "\n",
       "compound_id  compound_0009  compound_0010  ...  compound_1781  compound_1782  \\\n",
       "sample_0001      2139132.0       191212.0  ...         4.2410         2.9821   \n",
       "sample_0002      1680606.0       245996.0  ...         2.5322         2.9967   \n",
       "sample_0003      1757116.0       208971.0  ...         4.2848         3.3440   \n",
       "sample_0004      1655573.0       129250.0  ...         5.5764         4.3642   \n",
       "sample_0005      1845230.0       116337.0  ...         2.2900         2.3488   \n",
       "\n",
       "compound_id  compound_1783  compound_1784  compound_1785  compound_1786  \\\n",
       "sample_0001       202.3064         6.3900         9.4495      2368.6685   \n",
       "sample_0002       179.9669         5.8186         8.0212      1638.8876   \n",
       "sample_0003       168.2757         5.5424         7.1869      1716.4484   \n",
       "sample_0004       184.8738         5.8394         8.1066      1925.0035   \n",
       "sample_0005       110.1221         4.2770         7.0231      1336.6816   \n",
       "\n",
       "compound_id  compound_1787  compound_1788  compound_1789  compound_1790  \n",
       "sample_0001       174.0733        40.5750       484.9198      1771.8030  \n",
       "sample_0002       148.6103        27.8358       333.8163       980.4756  \n",
       "sample_0003       134.0830        28.4095       393.9803       418.6395  \n",
       "sample_0004       152.0123        26.4876       495.5018       738.0438  \n",
       "sample_0005        95.3169        16.4406       322.3633       586.9093  \n",
       "\n",
       "[5 rows x 1790 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.transpose()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31f7488e-5723-44cd-9ce1-12662df63065",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>compound_id</th>\n",
       "      <th>compound_0001</th>\n",
       "      <th>compound_0002</th>\n",
       "      <th>compound_0003</th>\n",
       "      <th>compound_0004</th>\n",
       "      <th>compound_0005</th>\n",
       "      <th>compound_0006</th>\n",
       "      <th>compound_0007</th>\n",
       "      <th>compound_0008</th>\n",
       "      <th>compound_0009</th>\n",
       "      <th>compound_0010</th>\n",
       "      <th>...</th>\n",
       "      <th>compound_1781</th>\n",
       "      <th>compound_1782</th>\n",
       "      <th>compound_1783</th>\n",
       "      <th>compound_1784</th>\n",
       "      <th>compound_1785</th>\n",
       "      <th>compound_1786</th>\n",
       "      <th>compound_1787</th>\n",
       "      <th>compound_1788</th>\n",
       "      <th>compound_1789</th>\n",
       "      <th>compound_1790</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.200000e+01</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>5.200000e+01</td>\n",
       "      <td>5.200000e+01</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>5.200000e+01</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>52.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>9.039227e+05</td>\n",
       "      <td>32339.057692</td>\n",
       "      <td>39250.615385</td>\n",
       "      <td>145139.134615</td>\n",
       "      <td>77730.384615</td>\n",
       "      <td>1.296888e+06</td>\n",
       "      <td>3.641979e+06</td>\n",
       "      <td>285558.576923</td>\n",
       "      <td>1.761902e+06</td>\n",
       "      <td>155856.692308</td>\n",
       "      <td>...</td>\n",
       "      <td>3.466821</td>\n",
       "      <td>2.931929</td>\n",
       "      <td>154.183117</td>\n",
       "      <td>5.472023</td>\n",
       "      <td>10.016440</td>\n",
       "      <td>1684.275827</td>\n",
       "      <td>137.594185</td>\n",
       "      <td>26.452858</td>\n",
       "      <td>369.187325</td>\n",
       "      <td>756.100358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.041032e+05</td>\n",
       "      <td>23464.336263</td>\n",
       "      <td>21927.963456</td>\n",
       "      <td>85653.316900</td>\n",
       "      <td>38276.562471</td>\n",
       "      <td>4.647482e+05</td>\n",
       "      <td>4.205837e+06</td>\n",
       "      <td>118081.318091</td>\n",
       "      <td>7.144546e+05</td>\n",
       "      <td>110733.303262</td>\n",
       "      <td>...</td>\n",
       "      <td>0.917163</td>\n",
       "      <td>0.677942</td>\n",
       "      <td>40.577034</td>\n",
       "      <td>1.864279</td>\n",
       "      <td>5.407366</td>\n",
       "      <td>422.272611</td>\n",
       "      <td>49.051842</td>\n",
       "      <td>8.453101</td>\n",
       "      <td>83.420511</td>\n",
       "      <td>456.306565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3.854370e+05</td>\n",
       "      <td>15061.000000</td>\n",
       "      <td>21318.000000</td>\n",
       "      <td>28964.000000</td>\n",
       "      <td>23037.000000</td>\n",
       "      <td>6.484610e+05</td>\n",
       "      <td>1.484940e+05</td>\n",
       "      <td>97803.000000</td>\n",
       "      <td>5.628200e+05</td>\n",
       "      <td>40151.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.623100</td>\n",
       "      <td>1.644300</td>\n",
       "      <td>58.887500</td>\n",
       "      <td>1.647200</td>\n",
       "      <td>6.164200</td>\n",
       "      <td>638.450400</td>\n",
       "      <td>30.357200</td>\n",
       "      <td>7.449700</td>\n",
       "      <td>173.080400</td>\n",
       "      <td>180.003000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.765188e+05</td>\n",
       "      <td>15061.000000</td>\n",
       "      <td>21318.000000</td>\n",
       "      <td>89914.000000</td>\n",
       "      <td>45793.750000</td>\n",
       "      <td>9.924350e+05</td>\n",
       "      <td>9.533482e+05</td>\n",
       "      <td>183987.000000</td>\n",
       "      <td>1.356778e+06</td>\n",
       "      <td>47712.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.856175</td>\n",
       "      <td>2.508975</td>\n",
       "      <td>130.283825</td>\n",
       "      <td>4.222525</td>\n",
       "      <td>7.326725</td>\n",
       "      <td>1435.102150</td>\n",
       "      <td>100.797050</td>\n",
       "      <td>20.058950</td>\n",
       "      <td>322.064500</td>\n",
       "      <td>454.159450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>8.507225e+05</td>\n",
       "      <td>24507.500000</td>\n",
       "      <td>28442.500000</td>\n",
       "      <td>120581.500000</td>\n",
       "      <td>68880.500000</td>\n",
       "      <td>1.184570e+06</td>\n",
       "      <td>2.091264e+06</td>\n",
       "      <td>267389.000000</td>\n",
       "      <td>1.682288e+06</td>\n",
       "      <td>128203.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.483950</td>\n",
       "      <td>2.970050</td>\n",
       "      <td>153.612450</td>\n",
       "      <td>5.450450</td>\n",
       "      <td>8.160200</td>\n",
       "      <td>1668.981050</td>\n",
       "      <td>139.337150</td>\n",
       "      <td>26.259500</td>\n",
       "      <td>355.140550</td>\n",
       "      <td>617.437550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.069312e+06</td>\n",
       "      <td>40041.250000</td>\n",
       "      <td>52346.750000</td>\n",
       "      <td>192340.250000</td>\n",
       "      <td>99393.500000</td>\n",
       "      <td>1.498860e+06</td>\n",
       "      <td>4.545380e+06</td>\n",
       "      <td>381386.250000</td>\n",
       "      <td>2.001750e+06</td>\n",
       "      <td>234940.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.070775</td>\n",
       "      <td>3.392000</td>\n",
       "      <td>180.316425</td>\n",
       "      <td>6.382425</td>\n",
       "      <td>9.428950</td>\n",
       "      <td>1972.751400</td>\n",
       "      <td>172.231675</td>\n",
       "      <td>30.985075</td>\n",
       "      <td>414.803475</td>\n",
       "      <td>946.654175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.638999e+06</td>\n",
       "      <td>115460.000000</td>\n",
       "      <td>101484.000000</td>\n",
       "      <td>441043.000000</td>\n",
       "      <td>185999.000000</td>\n",
       "      <td>3.232083e+06</td>\n",
       "      <td>2.553039e+07</td>\n",
       "      <td>531111.000000</td>\n",
       "      <td>4.109919e+06</td>\n",
       "      <td>515996.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>5.576400</td>\n",
       "      <td>4.901000</td>\n",
       "      <td>267.986000</td>\n",
       "      <td>9.689500</td>\n",
       "      <td>30.218100</td>\n",
       "      <td>2513.449200</td>\n",
       "      <td>239.921100</td>\n",
       "      <td>48.369800</td>\n",
       "      <td>565.346800</td>\n",
       "      <td>2016.189900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 1790 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "compound_id  compound_0001  compound_0002  compound_0003  compound_0004  \\\n",
       "count         5.200000e+01      52.000000      52.000000      52.000000   \n",
       "mean          9.039227e+05   32339.057692   39250.615385  145139.134615   \n",
       "std           3.041032e+05   23464.336263   21927.963456   85653.316900   \n",
       "min           3.854370e+05   15061.000000   21318.000000   28964.000000   \n",
       "25%           6.765188e+05   15061.000000   21318.000000   89914.000000   \n",
       "50%           8.507225e+05   24507.500000   28442.500000  120581.500000   \n",
       "75%           1.069312e+06   40041.250000   52346.750000  192340.250000   \n",
       "max           1.638999e+06  115460.000000  101484.000000  441043.000000   \n",
       "\n",
       "compound_id  compound_0005  compound_0006  compound_0007  compound_0008  \\\n",
       "count            52.000000   5.200000e+01   5.200000e+01      52.000000   \n",
       "mean          77730.384615   1.296888e+06   3.641979e+06  285558.576923   \n",
       "std           38276.562471   4.647482e+05   4.205837e+06  118081.318091   \n",
       "min           23037.000000   6.484610e+05   1.484940e+05   97803.000000   \n",
       "25%           45793.750000   9.924350e+05   9.533482e+05  183987.000000   \n",
       "50%           68880.500000   1.184570e+06   2.091264e+06  267389.000000   \n",
       "75%           99393.500000   1.498860e+06   4.545380e+06  381386.250000   \n",
       "max          185999.000000   3.232083e+06   2.553039e+07  531111.000000   \n",
       "\n",
       "compound_id  compound_0009  compound_0010  ...  compound_1781  compound_1782  \\\n",
       "count         5.200000e+01      52.000000  ...      52.000000      52.000000   \n",
       "mean          1.761902e+06  155856.692308  ...       3.466821       2.931929   \n",
       "std           7.144546e+05  110733.303262  ...       0.917163       0.677942   \n",
       "min           5.628200e+05   40151.000000  ...       1.623100       1.644300   \n",
       "25%           1.356778e+06   47712.500000  ...       2.856175       2.508975   \n",
       "50%           1.682288e+06  128203.500000  ...       3.483950       2.970050   \n",
       "75%           2.001750e+06  234940.000000  ...       4.070775       3.392000   \n",
       "max           4.109919e+06  515996.000000  ...       5.576400       4.901000   \n",
       "\n",
       "compound_id  compound_1783  compound_1784  compound_1785  compound_1786  \\\n",
       "count            52.000000      52.000000      52.000000      52.000000   \n",
       "mean            154.183117       5.472023      10.016440    1684.275827   \n",
       "std              40.577034       1.864279       5.407366     422.272611   \n",
       "min              58.887500       1.647200       6.164200     638.450400   \n",
       "25%             130.283825       4.222525       7.326725    1435.102150   \n",
       "50%             153.612450       5.450450       8.160200    1668.981050   \n",
       "75%             180.316425       6.382425       9.428950    1972.751400   \n",
       "max             267.986000       9.689500      30.218100    2513.449200   \n",
       "\n",
       "compound_id  compound_1787  compound_1788  compound_1789  compound_1790  \n",
       "count            52.000000      52.000000      52.000000      52.000000  \n",
       "mean            137.594185      26.452858     369.187325     756.100358  \n",
       "std              49.051842       8.453101      83.420511     456.306565  \n",
       "min              30.357200       7.449700     173.080400     180.003000  \n",
       "25%             100.797050      20.058950     322.064500     454.159450  \n",
       "50%             139.337150      26.259500     355.140550     617.437550  \n",
       "75%             172.231675      30.985075     414.803475     946.654175  \n",
       "max             239.921100      48.369800     565.346800    2016.189900  \n",
       "\n",
       "[8 rows x 1790 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f3d80f9-2f4f-49f3-8be5-38b91d00b501",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>health_status</th>\n",
       "      <th>sample_id_internal</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "      <th>Unnamed: 7</th>\n",
       "      <th>Unnamed: 8</th>\n",
       "      <th>Unnamed: 9</th>\n",
       "      <th>Unnamed: 10</th>\n",
       "      <th>Unnamed: 11</th>\n",
       "      <th>Unnamed: 12</th>\n",
       "      <th>Unnamed: 13</th>\n",
       "      <th>Unnamed: 14</th>\n",
       "      <th>Unnamed: 15</th>\n",
       "      <th>Unnamed: 16</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sample_0001</th>\n",
       "      <td>case</td>\n",
       "      <td>C1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample_0002</th>\n",
       "      <td>case</td>\n",
       "      <td>C2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample_0003</th>\n",
       "      <td>case</td>\n",
       "      <td>C3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample_0004</th>\n",
       "      <td>case</td>\n",
       "      <td>C4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample_0005</th>\n",
       "      <td>case</td>\n",
       "      <td>C5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            health_status sample_id_internal  Unnamed: 3  Unnamed: 4  \\\n",
       "sample_id                                                              \n",
       "sample_0001          case                 C1         NaN         NaN   \n",
       "sample_0002          case                 C2         NaN         NaN   \n",
       "sample_0003          case                 C3         NaN         NaN   \n",
       "sample_0004          case                 C4         NaN         NaN   \n",
       "sample_0005          case                 C5         NaN         NaN   \n",
       "\n",
       "             Unnamed: 5  Unnamed: 6  Unnamed: 7  Unnamed: 8  Unnamed: 9  \\\n",
       "sample_id                                                                 \n",
       "sample_0001         NaN         NaN         NaN         NaN         NaN   \n",
       "sample_0002         NaN         NaN         NaN         NaN         NaN   \n",
       "sample_0003         NaN         NaN         NaN         NaN         NaN   \n",
       "sample_0004         NaN         NaN         NaN         NaN         NaN   \n",
       "sample_0005         NaN         NaN         NaN         NaN         NaN   \n",
       "\n",
       "             Unnamed: 10  Unnamed: 11  Unnamed: 12  Unnamed: 13  Unnamed: 14  \\\n",
       "sample_id                                                                      \n",
       "sample_0001          NaN          NaN          NaN          NaN          NaN   \n",
       "sample_0002          NaN          NaN          NaN          NaN          NaN   \n",
       "sample_0003          NaN          NaN          NaN          NaN          NaN   \n",
       "sample_0004          NaN          NaN          NaN          NaN          NaN   \n",
       "sample_0005          NaN          NaN          NaN          NaN          NaN   \n",
       "\n",
       "             Unnamed: 15  Unnamed: 16  \n",
       "sample_id                              \n",
       "sample_0001          NaN          NaN  \n",
       "sample_0002          NaN          NaN  \n",
       "sample_0003          NaN          NaN  \n",
       "sample_0004          NaN          NaN  \n",
       "sample_0005          NaN          NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_labels = pd.read_csv('sample_metadata-Table 1.csv', sep=\";\", escapechar = '.',thousands = ',', index_col = 'sample_id')\n",
    "data_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1419595f-2111-4b60-bef8-a46ae0907b2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['health_status', 'sample_id_internal', 'Unnamed: 3', 'Unnamed: 4',\n",
       "       'Unnamed: 5', 'Unnamed: 6', 'Unnamed: 7', 'Unnamed: 8', 'Unnamed: 9',\n",
       "       'Unnamed: 10', 'Unnamed: 11', 'Unnamed: 12', 'Unnamed: 13',\n",
       "       'Unnamed: 14', 'Unnamed: 15', 'Unnamed: 16'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_labels.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7faaf9a-88d0-4d58-9830-427f14dbd11e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 52 entries, sample_0001 to sample_0052\n",
      "Data columns (total 2 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   health_status       52 non-null     object\n",
      " 1   sample_id_internal  52 non-null     object\n",
      "dtypes: object(2)\n",
      "memory usage: 1.2+ KB\n"
     ]
    }
   ],
   "source": [
    "data_labels = data_labels.drop(columns =['Unnamed: 3',\n",
    "       'Unnamed: 4', 'Unnamed: 5', 'Unnamed: 6', 'Unnamed: 7', 'Unnamed: 8',\n",
    "       'Unnamed: 9', 'Unnamed: 10', 'Unnamed: 11', 'Unnamed: 12',\n",
    "       'Unnamed: 13', 'Unnamed: 14', 'Unnamed: 15', 'Unnamed: 16'])\n",
    "data_labels.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72f1752c-7d9f-4582-85e0-87fb575f9edc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_id_internal</th>\n",
       "      <th>health_status_case</th>\n",
       "      <th>health_status_control</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sample_0001</th>\n",
       "      <td>C1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample_0002</th>\n",
       "      <td>C2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample_0003</th>\n",
       "      <td>C3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample_0004</th>\n",
       "      <td>C4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample_0005</th>\n",
       "      <td>C5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            sample_id_internal  health_status_case  health_status_control\n",
       "sample_id                                                                \n",
       "sample_0001                 C1                 1.0                    0.0\n",
       "sample_0002                 C2                 1.0                    0.0\n",
       "sample_0003                 C3                 1.0                    0.0\n",
       "sample_0004                 C4                 1.0                    0.0\n",
       "sample_0005                 C5                 1.0                    0.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_labels = pd.get_dummies(data_labels, columns=['health_status'], dtype = float)\n",
    "data_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b76d6fe0-e5fa-48c2-bbf2-5f05f93e93cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>compound_0001</th>\n",
       "      <th>compound_0002</th>\n",
       "      <th>compound_0003</th>\n",
       "      <th>compound_0004</th>\n",
       "      <th>compound_0005</th>\n",
       "      <th>compound_0006</th>\n",
       "      <th>compound_0007</th>\n",
       "      <th>compound_0008</th>\n",
       "      <th>compound_0009</th>\n",
       "      <th>compound_0010</th>\n",
       "      <th>...</th>\n",
       "      <th>compound_1782</th>\n",
       "      <th>compound_1783</th>\n",
       "      <th>compound_1784</th>\n",
       "      <th>compound_1785</th>\n",
       "      <th>compound_1786</th>\n",
       "      <th>compound_1787</th>\n",
       "      <th>compound_1788</th>\n",
       "      <th>compound_1789</th>\n",
       "      <th>compound_1790</th>\n",
       "      <th>health_status_case</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sample_0001</th>\n",
       "      <td>672039.0</td>\n",
       "      <td>74472.0</td>\n",
       "      <td>54758.0</td>\n",
       "      <td>230130.0</td>\n",
       "      <td>128065.0</td>\n",
       "      <td>1595220.0</td>\n",
       "      <td>1563524.0</td>\n",
       "      <td>306946.0</td>\n",
       "      <td>2139132.0</td>\n",
       "      <td>191212.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.9821</td>\n",
       "      <td>202.3064</td>\n",
       "      <td>6.3900</td>\n",
       "      <td>9.4495</td>\n",
       "      <td>2368.6685</td>\n",
       "      <td>174.0733</td>\n",
       "      <td>40.5750</td>\n",
       "      <td>484.9198</td>\n",
       "      <td>1771.8030</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample_0002</th>\n",
       "      <td>599392.0</td>\n",
       "      <td>23403.0</td>\n",
       "      <td>22374.0</td>\n",
       "      <td>112937.0</td>\n",
       "      <td>66968.0</td>\n",
       "      <td>911738.0</td>\n",
       "      <td>1761776.0</td>\n",
       "      <td>170567.0</td>\n",
       "      <td>1680606.0</td>\n",
       "      <td>245996.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.9967</td>\n",
       "      <td>179.9669</td>\n",
       "      <td>5.8186</td>\n",
       "      <td>8.0212</td>\n",
       "      <td>1638.8876</td>\n",
       "      <td>148.6103</td>\n",
       "      <td>27.8358</td>\n",
       "      <td>333.8163</td>\n",
       "      <td>980.4756</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample_0003</th>\n",
       "      <td>1023576.0</td>\n",
       "      <td>33924.0</td>\n",
       "      <td>57498.0</td>\n",
       "      <td>256586.0</td>\n",
       "      <td>92744.0</td>\n",
       "      <td>1242042.0</td>\n",
       "      <td>1495843.0</td>\n",
       "      <td>180168.0</td>\n",
       "      <td>1757116.0</td>\n",
       "      <td>208971.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.3440</td>\n",
       "      <td>168.2757</td>\n",
       "      <td>5.5424</td>\n",
       "      <td>7.1869</td>\n",
       "      <td>1716.4484</td>\n",
       "      <td>134.0830</td>\n",
       "      <td>28.4095</td>\n",
       "      <td>393.9803</td>\n",
       "      <td>418.6395</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample_0004</th>\n",
       "      <td>804353.0</td>\n",
       "      <td>15061.0</td>\n",
       "      <td>21318.0</td>\n",
       "      <td>62260.0</td>\n",
       "      <td>29284.0</td>\n",
       "      <td>1594599.0</td>\n",
       "      <td>1359280.0</td>\n",
       "      <td>219187.0</td>\n",
       "      <td>1655573.0</td>\n",
       "      <td>129250.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.3642</td>\n",
       "      <td>184.8738</td>\n",
       "      <td>5.8394</td>\n",
       "      <td>8.1066</td>\n",
       "      <td>1925.0035</td>\n",
       "      <td>152.0123</td>\n",
       "      <td>26.4876</td>\n",
       "      <td>495.5018</td>\n",
       "      <td>738.0438</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample_0005</th>\n",
       "      <td>557954.0</td>\n",
       "      <td>40816.0</td>\n",
       "      <td>58013.0</td>\n",
       "      <td>193937.0</td>\n",
       "      <td>100637.0</td>\n",
       "      <td>994207.0</td>\n",
       "      <td>3893889.0</td>\n",
       "      <td>307190.0</td>\n",
       "      <td>1845230.0</td>\n",
       "      <td>116337.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.3488</td>\n",
       "      <td>110.1221</td>\n",
       "      <td>4.2770</td>\n",
       "      <td>7.0231</td>\n",
       "      <td>1336.6816</td>\n",
       "      <td>95.3169</td>\n",
       "      <td>16.4406</td>\n",
       "      <td>322.3633</td>\n",
       "      <td>586.9093</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1791 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             compound_0001  compound_0002  compound_0003  compound_0004  \\\n",
       "sample_0001       672039.0        74472.0        54758.0       230130.0   \n",
       "sample_0002       599392.0        23403.0        22374.0       112937.0   \n",
       "sample_0003      1023576.0        33924.0        57498.0       256586.0   \n",
       "sample_0004       804353.0        15061.0        21318.0        62260.0   \n",
       "sample_0005       557954.0        40816.0        58013.0       193937.0   \n",
       "\n",
       "             compound_0005  compound_0006  compound_0007  compound_0008  \\\n",
       "sample_0001       128065.0      1595220.0      1563524.0       306946.0   \n",
       "sample_0002        66968.0       911738.0      1761776.0       170567.0   \n",
       "sample_0003        92744.0      1242042.0      1495843.0       180168.0   \n",
       "sample_0004        29284.0      1594599.0      1359280.0       219187.0   \n",
       "sample_0005       100637.0       994207.0      3893889.0       307190.0   \n",
       "\n",
       "             compound_0009  compound_0010  ...  compound_1782  compound_1783  \\\n",
       "sample_0001      2139132.0       191212.0  ...         2.9821       202.3064   \n",
       "sample_0002      1680606.0       245996.0  ...         2.9967       179.9669   \n",
       "sample_0003      1757116.0       208971.0  ...         3.3440       168.2757   \n",
       "sample_0004      1655573.0       129250.0  ...         4.3642       184.8738   \n",
       "sample_0005      1845230.0       116337.0  ...         2.3488       110.1221   \n",
       "\n",
       "             compound_1784  compound_1785  compound_1786  compound_1787  \\\n",
       "sample_0001         6.3900         9.4495      2368.6685       174.0733   \n",
       "sample_0002         5.8186         8.0212      1638.8876       148.6103   \n",
       "sample_0003         5.5424         7.1869      1716.4484       134.0830   \n",
       "sample_0004         5.8394         8.1066      1925.0035       152.0123   \n",
       "sample_0005         4.2770         7.0231      1336.6816        95.3169   \n",
       "\n",
       "             compound_1788  compound_1789  compound_1790  health_status_case  \n",
       "sample_0001        40.5750       484.9198      1771.8030                 1.0  \n",
       "sample_0002        27.8358       333.8163       980.4756                 1.0  \n",
       "sample_0003        28.4095       393.9803       418.6395                 1.0  \n",
       "sample_0004        26.4876       495.5018       738.0438                 1.0  \n",
       "sample_0005        16.4406       322.3633       586.9093                 1.0  \n",
       "\n",
       "[5 rows x 1791 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_full = pd.concat([data,data_labels['health_status_case']], axis = 1)\n",
    "data_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4bd8d539-c630-4db4-946b-edf2b4e77a66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>compound_0001</th>\n",
       "      <th>compound_0002</th>\n",
       "      <th>compound_0003</th>\n",
       "      <th>compound_0004</th>\n",
       "      <th>compound_0005</th>\n",
       "      <th>compound_0006</th>\n",
       "      <th>compound_0007</th>\n",
       "      <th>compound_0008</th>\n",
       "      <th>compound_0009</th>\n",
       "      <th>compound_0010</th>\n",
       "      <th>...</th>\n",
       "      <th>compound_1782</th>\n",
       "      <th>compound_1783</th>\n",
       "      <th>compound_1784</th>\n",
       "      <th>compound_1785</th>\n",
       "      <th>compound_1786</th>\n",
       "      <th>compound_1787</th>\n",
       "      <th>compound_1788</th>\n",
       "      <th>compound_1789</th>\n",
       "      <th>compound_1790</th>\n",
       "      <th>health_status_case</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sample_0048</th>\n",
       "      <td>1014031.0</td>\n",
       "      <td>43291.0</td>\n",
       "      <td>74266.0</td>\n",
       "      <td>228867.0</td>\n",
       "      <td>132303.0</td>\n",
       "      <td>1497081.0</td>\n",
       "      <td>2008853.0</td>\n",
       "      <td>435096.0</td>\n",
       "      <td>1844785.0</td>\n",
       "      <td>284632.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.7913</td>\n",
       "      <td>172.9869</td>\n",
       "      <td>6.2761</td>\n",
       "      <td>7.2179</td>\n",
       "      <td>2009.8961</td>\n",
       "      <td>184.8696</td>\n",
       "      <td>29.7098</td>\n",
       "      <td>537.0563</td>\n",
       "      <td>766.5373</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample_0049</th>\n",
       "      <td>678012.0</td>\n",
       "      <td>26561.0</td>\n",
       "      <td>38397.0</td>\n",
       "      <td>113867.0</td>\n",
       "      <td>90500.0</td>\n",
       "      <td>2387276.0</td>\n",
       "      <td>8871935.0</td>\n",
       "      <td>337506.0</td>\n",
       "      <td>3609518.0</td>\n",
       "      <td>40151.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.9640</td>\n",
       "      <td>133.2139</td>\n",
       "      <td>3.1823</td>\n",
       "      <td>6.4743</td>\n",
       "      <td>1453.6886</td>\n",
       "      <td>117.0809</td>\n",
       "      <td>19.8986</td>\n",
       "      <td>384.7017</td>\n",
       "      <td>646.5598</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample_0050</th>\n",
       "      <td>385437.0</td>\n",
       "      <td>15061.0</td>\n",
       "      <td>21318.0</td>\n",
       "      <td>29731.0</td>\n",
       "      <td>23037.0</td>\n",
       "      <td>956490.0</td>\n",
       "      <td>5771395.0</td>\n",
       "      <td>129100.0</td>\n",
       "      <td>918962.0</td>\n",
       "      <td>80370.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.5585</td>\n",
       "      <td>120.9511</td>\n",
       "      <td>3.6443</td>\n",
       "      <td>8.1645</td>\n",
       "      <td>948.5136</td>\n",
       "      <td>48.4216</td>\n",
       "      <td>15.0524</td>\n",
       "      <td>252.0705</td>\n",
       "      <td>263.5224</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample_0051</th>\n",
       "      <td>1019252.0</td>\n",
       "      <td>72704.0</td>\n",
       "      <td>68930.0</td>\n",
       "      <td>283890.0</td>\n",
       "      <td>132772.0</td>\n",
       "      <td>1623758.0</td>\n",
       "      <td>9805331.0</td>\n",
       "      <td>327770.0</td>\n",
       "      <td>2754873.0</td>\n",
       "      <td>72560.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.8508</td>\n",
       "      <td>164.4916</td>\n",
       "      <td>7.8184</td>\n",
       "      <td>7.3316</td>\n",
       "      <td>1870.4915</td>\n",
       "      <td>239.9211</td>\n",
       "      <td>34.7575</td>\n",
       "      <td>352.4500</td>\n",
       "      <td>2016.1899</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample_0052</th>\n",
       "      <td>434933.0</td>\n",
       "      <td>39783.0</td>\n",
       "      <td>26156.0</td>\n",
       "      <td>90141.0</td>\n",
       "      <td>66803.0</td>\n",
       "      <td>1027606.0</td>\n",
       "      <td>472887.0</td>\n",
       "      <td>199756.0</td>\n",
       "      <td>1103439.0</td>\n",
       "      <td>515996.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.7229</td>\n",
       "      <td>153.2060</td>\n",
       "      <td>4.8656</td>\n",
       "      <td>7.8141</td>\n",
       "      <td>1813.6272</td>\n",
       "      <td>166.1732</td>\n",
       "      <td>28.2014</td>\n",
       "      <td>431.4605</td>\n",
       "      <td>527.2179</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1791 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             compound_0001  compound_0002  compound_0003  compound_0004  \\\n",
       "sample_0048      1014031.0        43291.0        74266.0       228867.0   \n",
       "sample_0049       678012.0        26561.0        38397.0       113867.0   \n",
       "sample_0050       385437.0        15061.0        21318.0        29731.0   \n",
       "sample_0051      1019252.0        72704.0        68930.0       283890.0   \n",
       "sample_0052       434933.0        39783.0        26156.0        90141.0   \n",
       "\n",
       "             compound_0005  compound_0006  compound_0007  compound_0008  \\\n",
       "sample_0048       132303.0      1497081.0      2008853.0       435096.0   \n",
       "sample_0049        90500.0      2387276.0      8871935.0       337506.0   \n",
       "sample_0050        23037.0       956490.0      5771395.0       129100.0   \n",
       "sample_0051       132772.0      1623758.0      9805331.0       327770.0   \n",
       "sample_0052        66803.0      1027606.0       472887.0       199756.0   \n",
       "\n",
       "             compound_0009  compound_0010  ...  compound_1782  compound_1783  \\\n",
       "sample_0048      1844785.0       284632.0  ...         3.7913       172.9869   \n",
       "sample_0049      3609518.0        40151.0  ...         2.9640       133.2139   \n",
       "sample_0050       918962.0        80370.0  ...         2.5585       120.9511   \n",
       "sample_0051      2754873.0        72560.0  ...         1.8508       164.4916   \n",
       "sample_0052      1103439.0       515996.0  ...         3.7229       153.2060   \n",
       "\n",
       "             compound_1784  compound_1785  compound_1786  compound_1787  \\\n",
       "sample_0048         6.2761         7.2179      2009.8961       184.8696   \n",
       "sample_0049         3.1823         6.4743      1453.6886       117.0809   \n",
       "sample_0050         3.6443         8.1645       948.5136        48.4216   \n",
       "sample_0051         7.8184         7.3316      1870.4915       239.9211   \n",
       "sample_0052         4.8656         7.8141      1813.6272       166.1732   \n",
       "\n",
       "             compound_1788  compound_1789  compound_1790  health_status_case  \n",
       "sample_0048        29.7098       537.0563       766.5373                 0.0  \n",
       "sample_0049        19.8986       384.7017       646.5598                 0.0  \n",
       "sample_0050        15.0524       252.0705       263.5224                 0.0  \n",
       "sample_0051        34.7575       352.4500      2016.1899                 0.0  \n",
       "sample_0052        28.2014       431.4605       527.2179                 0.0  \n",
       "\n",
       "[5 rows x 1791 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_full.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a5a4b13-9326-4101-ac06-926d8bcb53f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 52 entries, sample_0001 to sample_0052\n",
      "Columns: 1791 entries, compound_0001 to health_status_case\n",
      "dtypes: float64(1791)\n",
      "memory usage: 730.1+ KB\n"
     ]
    }
   ],
   "source": [
    "data_full.convert_dtypes()\n",
    "data_full.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e9c71fe7-e619-4555-b10d-e2604b2e9a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "import keras\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5118b429-2504-4209-ab88-2c9bd205a4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_full.iloc[:, :-1]\n",
    "y = data_full.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5d4e6b07-4e1f-485f-bbdb-3d7784c14fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, data_test, label_train, label_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a0bcec94-f12a-43ab-9323-d4f1f2e1ab6d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>compound_0001</th>\n",
       "      <th>compound_0002</th>\n",
       "      <th>compound_0003</th>\n",
       "      <th>compound_0004</th>\n",
       "      <th>compound_0005</th>\n",
       "      <th>compound_0006</th>\n",
       "      <th>compound_0007</th>\n",
       "      <th>compound_0008</th>\n",
       "      <th>compound_0009</th>\n",
       "      <th>compound_0010</th>\n",
       "      <th>...</th>\n",
       "      <th>compound_1781</th>\n",
       "      <th>compound_1782</th>\n",
       "      <th>compound_1783</th>\n",
       "      <th>compound_1784</th>\n",
       "      <th>compound_1785</th>\n",
       "      <th>compound_1786</th>\n",
       "      <th>compound_1787</th>\n",
       "      <th>compound_1788</th>\n",
       "      <th>compound_1789</th>\n",
       "      <th>compound_1790</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sample_0025</th>\n",
       "      <td>668638.0</td>\n",
       "      <td>38344.0</td>\n",
       "      <td>45696.0</td>\n",
       "      <td>206052.0</td>\n",
       "      <td>89556.0</td>\n",
       "      <td>1504195.0</td>\n",
       "      <td>3076594.0</td>\n",
       "      <td>153954.0</td>\n",
       "      <td>1297713.0</td>\n",
       "      <td>40151.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.5502</td>\n",
       "      <td>2.9910</td>\n",
       "      <td>148.6146</td>\n",
       "      <td>6.0154</td>\n",
       "      <td>29.3850</td>\n",
       "      <td>1476.8319</td>\n",
       "      <td>148.8325</td>\n",
       "      <td>22.1839</td>\n",
       "      <td>344.8457</td>\n",
       "      <td>598.6491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample_0007</th>\n",
       "      <td>927166.0</td>\n",
       "      <td>15061.0</td>\n",
       "      <td>21318.0</td>\n",
       "      <td>67179.0</td>\n",
       "      <td>23037.0</td>\n",
       "      <td>859693.0</td>\n",
       "      <td>3271915.0</td>\n",
       "      <td>223990.0</td>\n",
       "      <td>1456673.0</td>\n",
       "      <td>268500.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0651</td>\n",
       "      <td>3.4054</td>\n",
       "      <td>192.7260</td>\n",
       "      <td>6.3799</td>\n",
       "      <td>7.9646</td>\n",
       "      <td>1455.0098</td>\n",
       "      <td>93.5323</td>\n",
       "      <td>24.2079</td>\n",
       "      <td>348.5360</td>\n",
       "      <td>253.1985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample_0030</th>\n",
       "      <td>1625984.0</td>\n",
       "      <td>20590.0</td>\n",
       "      <td>30507.0</td>\n",
       "      <td>149117.0</td>\n",
       "      <td>46180.0</td>\n",
       "      <td>1051322.0</td>\n",
       "      <td>259616.0</td>\n",
       "      <td>207736.0</td>\n",
       "      <td>1497166.0</td>\n",
       "      <td>78272.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.5695</td>\n",
       "      <td>4.9010</td>\n",
       "      <td>189.6124</td>\n",
       "      <td>5.5313</td>\n",
       "      <td>6.6911</td>\n",
       "      <td>1780.0061</td>\n",
       "      <td>77.0022</td>\n",
       "      <td>30.7733</td>\n",
       "      <td>411.9475</td>\n",
       "      <td>281.8036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample_0008</th>\n",
       "      <td>1088624.0</td>\n",
       "      <td>26107.0</td>\n",
       "      <td>34094.0</td>\n",
       "      <td>105097.0</td>\n",
       "      <td>93367.0</td>\n",
       "      <td>1305644.0</td>\n",
       "      <td>25530392.0</td>\n",
       "      <td>531111.0</td>\n",
       "      <td>1921994.0</td>\n",
       "      <td>247497.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0464</td>\n",
       "      <td>2.3722</td>\n",
       "      <td>145.8720</td>\n",
       "      <td>4.5568</td>\n",
       "      <td>22.2994</td>\n",
       "      <td>1635.9086</td>\n",
       "      <td>170.7266</td>\n",
       "      <td>23.4531</td>\n",
       "      <td>359.4800</td>\n",
       "      <td>551.9124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample_0051</th>\n",
       "      <td>1019252.0</td>\n",
       "      <td>72704.0</td>\n",
       "      <td>68930.0</td>\n",
       "      <td>283890.0</td>\n",
       "      <td>132772.0</td>\n",
       "      <td>1623758.0</td>\n",
       "      <td>9805331.0</td>\n",
       "      <td>327770.0</td>\n",
       "      <td>2754873.0</td>\n",
       "      <td>72560.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.2453</td>\n",
       "      <td>1.8508</td>\n",
       "      <td>164.4916</td>\n",
       "      <td>7.8184</td>\n",
       "      <td>7.3316</td>\n",
       "      <td>1870.4915</td>\n",
       "      <td>239.9211</td>\n",
       "      <td>34.7575</td>\n",
       "      <td>352.4500</td>\n",
       "      <td>2016.1899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample_0026</th>\n",
       "      <td>924595.0</td>\n",
       "      <td>15061.0</td>\n",
       "      <td>21318.0</td>\n",
       "      <td>102811.0</td>\n",
       "      <td>42055.0</td>\n",
       "      <td>1072363.0</td>\n",
       "      <td>232338.0</td>\n",
       "      <td>165225.0</td>\n",
       "      <td>1900635.0</td>\n",
       "      <td>152855.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.7809</td>\n",
       "      <td>2.6307</td>\n",
       "      <td>191.6180</td>\n",
       "      <td>5.9063</td>\n",
       "      <td>8.3842</td>\n",
       "      <td>1639.7271</td>\n",
       "      <td>112.8239</td>\n",
       "      <td>30.3624</td>\n",
       "      <td>328.2103</td>\n",
       "      <td>710.0678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample_0021</th>\n",
       "      <td>1187545.0</td>\n",
       "      <td>15061.0</td>\n",
       "      <td>21318.0</td>\n",
       "      <td>61002.0</td>\n",
       "      <td>47254.0</td>\n",
       "      <td>1718252.0</td>\n",
       "      <td>8038109.0</td>\n",
       "      <td>383370.0</td>\n",
       "      <td>2145181.0</td>\n",
       "      <td>40151.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.1589</td>\n",
       "      <td>1.8674</td>\n",
       "      <td>131.3858</td>\n",
       "      <td>3.7255</td>\n",
       "      <td>7.9911</td>\n",
       "      <td>1178.7789</td>\n",
       "      <td>106.3329</td>\n",
       "      <td>20.1124</td>\n",
       "      <td>305.3951</td>\n",
       "      <td>496.9968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample_0005</th>\n",
       "      <td>557954.0</td>\n",
       "      <td>40816.0</td>\n",
       "      <td>58013.0</td>\n",
       "      <td>193937.0</td>\n",
       "      <td>100637.0</td>\n",
       "      <td>994207.0</td>\n",
       "      <td>3893889.0</td>\n",
       "      <td>307190.0</td>\n",
       "      <td>1845230.0</td>\n",
       "      <td>116337.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.2900</td>\n",
       "      <td>2.3488</td>\n",
       "      <td>110.1221</td>\n",
       "      <td>4.2770</td>\n",
       "      <td>7.0231</td>\n",
       "      <td>1336.6816</td>\n",
       "      <td>95.3169</td>\n",
       "      <td>16.4406</td>\n",
       "      <td>322.3633</td>\n",
       "      <td>586.9093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample_0012</th>\n",
       "      <td>886869.0</td>\n",
       "      <td>15061.0</td>\n",
       "      <td>21318.0</td>\n",
       "      <td>47368.0</td>\n",
       "      <td>27322.0</td>\n",
       "      <td>648461.0</td>\n",
       "      <td>148494.0</td>\n",
       "      <td>190944.0</td>\n",
       "      <td>1179061.0</td>\n",
       "      <td>182952.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.4486</td>\n",
       "      <td>2.7738</td>\n",
       "      <td>85.3464</td>\n",
       "      <td>2.6988</td>\n",
       "      <td>6.4856</td>\n",
       "      <td>1424.4583</td>\n",
       "      <td>61.8817</td>\n",
       "      <td>17.7114</td>\n",
       "      <td>298.6204</td>\n",
       "      <td>237.0311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample_0015</th>\n",
       "      <td>804398.0</td>\n",
       "      <td>25612.0</td>\n",
       "      <td>21318.0</td>\n",
       "      <td>91207.0</td>\n",
       "      <td>63143.0</td>\n",
       "      <td>1578412.0</td>\n",
       "      <td>8125072.0</td>\n",
       "      <td>414395.0</td>\n",
       "      <td>2143277.0</td>\n",
       "      <td>127157.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.9347</td>\n",
       "      <td>2.4705</td>\n",
       "      <td>204.3848</td>\n",
       "      <td>7.7395</td>\n",
       "      <td>8.6076</td>\n",
       "      <td>1829.3821</td>\n",
       "      <td>160.0544</td>\n",
       "      <td>27.8742</td>\n",
       "      <td>307.0129</td>\n",
       "      <td>519.4801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample_0013</th>\n",
       "      <td>1081265.0</td>\n",
       "      <td>15061.0</td>\n",
       "      <td>47262.0</td>\n",
       "      <td>141936.0</td>\n",
       "      <td>82848.0</td>\n",
       "      <td>1291228.0</td>\n",
       "      <td>4320473.0</td>\n",
       "      <td>380725.0</td>\n",
       "      <td>1402865.0</td>\n",
       "      <td>403364.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.9961</td>\n",
       "      <td>3.6126</td>\n",
       "      <td>262.7088</td>\n",
       "      <td>9.1188</td>\n",
       "      <td>7.3959</td>\n",
       "      <td>2115.3879</td>\n",
       "      <td>165.6552</td>\n",
       "      <td>28.4126</td>\n",
       "      <td>427.7689</td>\n",
       "      <td>180.0030</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11 rows × 1790 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             compound_0001  compound_0002  compound_0003  compound_0004  \\\n",
       "sample_0025       668638.0        38344.0        45696.0       206052.0   \n",
       "sample_0007       927166.0        15061.0        21318.0        67179.0   \n",
       "sample_0030      1625984.0        20590.0        30507.0       149117.0   \n",
       "sample_0008      1088624.0        26107.0        34094.0       105097.0   \n",
       "sample_0051      1019252.0        72704.0        68930.0       283890.0   \n",
       "sample_0026       924595.0        15061.0        21318.0       102811.0   \n",
       "sample_0021      1187545.0        15061.0        21318.0        61002.0   \n",
       "sample_0005       557954.0        40816.0        58013.0       193937.0   \n",
       "sample_0012       886869.0        15061.0        21318.0        47368.0   \n",
       "sample_0015       804398.0        25612.0        21318.0        91207.0   \n",
       "sample_0013      1081265.0        15061.0        47262.0       141936.0   \n",
       "\n",
       "             compound_0005  compound_0006  compound_0007  compound_0008  \\\n",
       "sample_0025        89556.0      1504195.0      3076594.0       153954.0   \n",
       "sample_0007        23037.0       859693.0      3271915.0       223990.0   \n",
       "sample_0030        46180.0      1051322.0       259616.0       207736.0   \n",
       "sample_0008        93367.0      1305644.0     25530392.0       531111.0   \n",
       "sample_0051       132772.0      1623758.0      9805331.0       327770.0   \n",
       "sample_0026        42055.0      1072363.0       232338.0       165225.0   \n",
       "sample_0021        47254.0      1718252.0      8038109.0       383370.0   \n",
       "sample_0005       100637.0       994207.0      3893889.0       307190.0   \n",
       "sample_0012        27322.0       648461.0       148494.0       190944.0   \n",
       "sample_0015        63143.0      1578412.0      8125072.0       414395.0   \n",
       "sample_0013        82848.0      1291228.0      4320473.0       380725.0   \n",
       "\n",
       "             compound_0009  compound_0010  ...  compound_1781  compound_1782  \\\n",
       "sample_0025      1297713.0        40151.0  ...         3.5502         2.9910   \n",
       "sample_0007      1456673.0       268500.0  ...         4.0651         3.4054   \n",
       "sample_0030      1497166.0        78272.0  ...         4.5695         4.9010   \n",
       "sample_0008      1921994.0       247497.0  ...         3.0464         2.3722   \n",
       "sample_0051      2754873.0        72560.0  ...         3.2453         1.8508   \n",
       "sample_0026      1900635.0       152855.0  ...         2.7809         2.6307   \n",
       "sample_0021      2145181.0        40151.0  ...         2.1589         1.8674   \n",
       "sample_0005      1845230.0       116337.0  ...         2.2900         2.3488   \n",
       "sample_0012      1179061.0       182952.0  ...         3.4486         2.7738   \n",
       "sample_0015      2143277.0       127157.0  ...         2.9347         2.4705   \n",
       "sample_0013      1402865.0       403364.0  ...         3.9961         3.6126   \n",
       "\n",
       "             compound_1783  compound_1784  compound_1785  compound_1786  \\\n",
       "sample_0025       148.6146         6.0154        29.3850      1476.8319   \n",
       "sample_0007       192.7260         6.3799         7.9646      1455.0098   \n",
       "sample_0030       189.6124         5.5313         6.6911      1780.0061   \n",
       "sample_0008       145.8720         4.5568        22.2994      1635.9086   \n",
       "sample_0051       164.4916         7.8184         7.3316      1870.4915   \n",
       "sample_0026       191.6180         5.9063         8.3842      1639.7271   \n",
       "sample_0021       131.3858         3.7255         7.9911      1178.7789   \n",
       "sample_0005       110.1221         4.2770         7.0231      1336.6816   \n",
       "sample_0012        85.3464         2.6988         6.4856      1424.4583   \n",
       "sample_0015       204.3848         7.7395         8.6076      1829.3821   \n",
       "sample_0013       262.7088         9.1188         7.3959      2115.3879   \n",
       "\n",
       "             compound_1787  compound_1788  compound_1789  compound_1790  \n",
       "sample_0025       148.8325        22.1839       344.8457       598.6491  \n",
       "sample_0007        93.5323        24.2079       348.5360       253.1985  \n",
       "sample_0030        77.0022        30.7733       411.9475       281.8036  \n",
       "sample_0008       170.7266        23.4531       359.4800       551.9124  \n",
       "sample_0051       239.9211        34.7575       352.4500      2016.1899  \n",
       "sample_0026       112.8239        30.3624       328.2103       710.0678  \n",
       "sample_0021       106.3329        20.1124       305.3951       496.9968  \n",
       "sample_0005        95.3169        16.4406       322.3633       586.9093  \n",
       "sample_0012        61.8817        17.7114       298.6204       237.0311  \n",
       "sample_0015       160.0544        27.8742       307.0129       519.4801  \n",
       "sample_0013       165.6552        28.4126       427.7689       180.0030  \n",
       "\n",
       "[11 rows x 1790 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1be8adb7-627a-4a32-a024-ff988ed5c64f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sample_0042    0.0\n",
       "sample_0023    1.0\n",
       "sample_0017    1.0\n",
       "sample_0036    0.0\n",
       "sample_0032    0.0\n",
       "sample_0034    0.0\n",
       "sample_0016    1.0\n",
       "sample_0019    1.0\n",
       "sample_0045    0.0\n",
       "sample_0029    0.0\n",
       "sample_0028    0.0\n",
       "sample_0050    0.0\n",
       "sample_0014    1.0\n",
       "sample_0011    1.0\n",
       "sample_0020    1.0\n",
       "sample_0033    0.0\n",
       "sample_0043    0.0\n",
       "sample_0048    0.0\n",
       "sample_0027    0.0\n",
       "sample_0035    0.0\n",
       "sample_0018    1.0\n",
       "sample_0052    0.0\n",
       "sample_0044    0.0\n",
       "sample_0003    1.0\n",
       "sample_0046    0.0\n",
       "sample_0038    0.0\n",
       "sample_0022    1.0\n",
       "sample_0001    1.0\n",
       "sample_0004    1.0\n",
       "sample_0039    0.0\n",
       "sample_0037    0.0\n",
       "sample_0049    0.0\n",
       "sample_0031    0.0\n",
       "sample_0040    0.0\n",
       "sample_0010    1.0\n",
       "sample_0009    1.0\n",
       "sample_0024    1.0\n",
       "sample_0041    0.0\n",
       "sample_0002    1.0\n",
       "sample_0006    1.0\n",
       "sample_0047    0.0\n",
       "Name: health_status_case, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96568510-2fb9-41bf-8d1d-84e2c0b78689",
   "metadata": {},
   "source": [
    "## ML models for Classification with sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1f352495-b931-4b48-ae03-0a40ab6797b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.45454545454545453\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.17      0.50      0.25         2\n",
      "         1.0       0.80      0.44      0.57         9\n",
      "\n",
      "    accuracy                           0.45        11\n",
      "   macro avg       0.48      0.47      0.41        11\n",
      "weighted avg       0.68      0.45      0.51        11\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "data_train = scaler.fit_transform(data_train)\n",
    "data_test = scaler.fit_transform(data_test)\n",
    "\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(data_train, label_train)\n",
    "\n",
    "y_pred = model.predict(data_test)\n",
    "print(\"Accuracy:\", accuracy_score(label_test, y_pred))\n",
    "print(classification_report(label_test, y_pred))\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "886a5883-fb49-4da7-85b6-0e62cb3f397c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.18181818181818182\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.11      0.50      0.18         2\n",
      "         1.0       0.50      0.11      0.18         9\n",
      "\n",
      "    accuracy                           0.18        11\n",
      "   macro avg       0.31      0.31      0.18        11\n",
      "weighted avg       0.43      0.18      0.18        11\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(data_train, label_train)\n",
    "y_pred_knn = knn.predict(data_test)\n",
    "print(\"Accuracy:\", accuracy_score(label_test, y_pred_knn))\n",
    "print(classification_report(label_test, y_pred_knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4a9ed083-3095-450f-8b0a-e697e80f6844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7272727272727273\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.40      1.00      0.57         2\n",
      "         1.0       1.00      0.67      0.80         9\n",
      "\n",
      "    accuracy                           0.73        11\n",
      "   macro avg       0.70      0.83      0.69        11\n",
      "weighted avg       0.89      0.73      0.76        11\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "tree = DecisionTreeClassifier(max_depth=5)\n",
    "tree.fit(data_train, label_train)\n",
    "y_pred_tree = tree.predict(data_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(label_test, y_pred_tree))\n",
    "print(classification_report(label_test, y_pred_tree))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f01a843d-52d1-4458-bf56-36bdd9a70813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.36363636363636365\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.22      1.00      0.36         2\n",
      "         1.0       1.00      0.22      0.36         9\n",
      "\n",
      "    accuracy                           0.36        11\n",
      "   macro avg       0.61      0.61      0.36        11\n",
      "weighted avg       0.86      0.36      0.36        11\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "forest = RandomForestClassifier(n_estimators=100, max_depth=7, random_state=42)\n",
    "forest.fit(data_train, label_train)\n",
    "\n",
    "y_pred_forest = forest.predict(data_test)\n",
    "print(\"Accuracy:\", accuracy_score(label_test, y_pred_forest))\n",
    "print(classification_report(label_test, y_pred_forest))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7f016dff-8657-42ee-bd57-84fb8600f6dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.2727272727272727\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.20      1.00      0.33         2\n",
      "         1.0       1.00      0.11      0.20         9\n",
      "\n",
      "    accuracy                           0.27        11\n",
      "   macro avg       0.60      0.56      0.27        11\n",
      "weighted avg       0.85      0.27      0.22        11\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "nb = GaussianNB()\n",
    "nb.fit(data_train, label_train)\n",
    "y_pred_nb = nb.predict(data_test)\n",
    "print(\"Accuracy:\", accuracy_score(label_test, y_pred_nb))\n",
    "print(classification_report(label_test, y_pred_nb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bbc79e9b-3985-487a-a94a-7982e12bb20a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.45454545454545453\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.25      1.00      0.40         2\n",
      "         1.0       1.00      0.33      0.50         9\n",
      "\n",
      "    accuracy                           0.45        11\n",
      "   macro avg       0.62      0.67      0.45        11\n",
      "weighted avg       0.86      0.45      0.48        11\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gb = GradientBoostingClassifier(n_estimators=200, learning_rate=1, max_depth=1, random_state=42)\n",
    "gb.fit(data_train, label_train)\n",
    "y_pred_gb = gb.predict(data_test)\n",
    "print(\"Accuracy:\", accuracy_score(label_test, y_pred_gb))\n",
    "print(classification_report(label_test, y_pred_gb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "99a658e0-8d81-49e2-8821-dd46826ab329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[1 1]\n",
      " [5 4]]\n",
      "Precision: 0.6848484848484848\n",
      "Recall: 0.45454545454545453\n",
      "F1-Score: 0.512987012987013\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
    "\n",
    "cm = confusion_matrix(label_test, y_pred)\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "\n",
    "precision = precision_score(label_test, y_pred, average='weighted')\n",
    "print(\"Precision:\", precision)\n",
    "\n",
    "recall = recall_score(label_test, y_pred, average='weighted')\n",
    "print(\"Recall:\", recall)\n",
    "\n",
    "f1 = f1_score(label_test, y_pred, average='weighted')\n",
    "print(\"F1-Score:\", f1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84fe32c-f017-4717-81e2-7c637cf904d0",
   "metadata": {},
   "source": [
    "## Deep Learning models for Classification with sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7c6b44f1-1055-4209-9926-4ed79c728206",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(alpha=1e-06, batch_size=11, hidden_layer_sizes=(16, 24, 2),\n",
       "              learning_rate_init=0.0001, max_iter=400, random_state=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;MLPClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.neural_network.MLPClassifier.html\">?<span>Documentation for MLPClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>MLPClassifier(alpha=1e-06, batch_size=11, hidden_layer_sizes=(16, 24, 2),\n",
       "              learning_rate_init=0.0001, max_iter=400, random_state=1)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "MLPClassifier(alpha=1e-06, batch_size=11, hidden_layer_sizes=(16, 24, 2),\n",
       "              learning_rate_init=0.0001, max_iter=400, random_state=1)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "clf = MLPClassifier(solver='adam', alpha=1e-6, learning_rate_init = 0.0001, max_iter= 400, batch_size= 11,\n",
    "                    hidden_layer_sizes=(16, 24, 2), random_state=1)\n",
    "\n",
    "clf.fit(data_train, label_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6a1ee158-572b-4703-93e9-6caf14bf535e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0.])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0e15b11b-f5f3-4122-80f8-ad0536f29988",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6363636363636364"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(data_test, label_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b408489f-2076-45a5-875e-d1f3e5cbea2e",
   "metadata": {},
   "source": [
    "### Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cebf995a-50c0-4f77-9f93-c1ac0721402b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    compound_0001  compound_0002  compound_0003  \\\n",
      "compound_0001            1.000000      -0.088426      -0.006791   \n",
      "compound_0002           -0.088426       1.000000       0.830037   \n",
      "compound_0003           -0.006791       0.830037       1.000000   \n",
      "compound_0004            0.015976       0.703266       0.734315   \n",
      "compound_0005           -0.043430       0.898954       0.884352   \n",
      "...                           ...            ...            ...   \n",
      "compound_1787           -0.042484       0.465870       0.394920   \n",
      "compound_1788           -0.120095       0.424939       0.383943   \n",
      "compound_1789            0.077883       0.429818       0.498214   \n",
      "compound_1790           -0.102652       0.495085       0.391304   \n",
      "health_status_case       0.048742      -0.205328      -0.281018   \n",
      "\n",
      "                    compound_0004  compound_0005  compound_0006  \\\n",
      "compound_0001            0.015976      -0.043430      -0.047759   \n",
      "compound_0002            0.703266       0.898954       0.282544   \n",
      "compound_0003            0.734315       0.884352       0.362916   \n",
      "compound_0004            1.000000       0.814208       0.510215   \n",
      "compound_0005            0.814208       1.000000       0.401477   \n",
      "...                           ...            ...            ...   \n",
      "compound_1787            0.495689       0.573863       0.376968   \n",
      "compound_1788            0.480303       0.460999       0.301672   \n",
      "compound_1789            0.500414       0.518997       0.342285   \n",
      "compound_1790            0.386951       0.513177       0.272855   \n",
      "health_status_case      -0.237960      -0.215671      -0.224329   \n",
      "\n",
      "                    compound_0007  compound_0008  compound_0009  \\\n",
      "compound_0001            0.121177       0.247632      -0.039972   \n",
      "compound_0002            0.095607       0.431098       0.233410   \n",
      "compound_0003            0.064976       0.414478       0.225766   \n",
      "compound_0004            0.017749       0.344542       0.438087   \n",
      "compound_0005            0.177882       0.493821       0.328760   \n",
      "...                           ...            ...            ...   \n",
      "compound_1787            0.221102       0.511734       0.465362   \n",
      "compound_1788            0.004271       0.268514       0.438493   \n",
      "compound_1789           -0.005513       0.416872       0.264808   \n",
      "compound_1790            0.038318       0.239910       0.408653   \n",
      "health_status_case       0.112007      -0.082211      -0.130698   \n",
      "\n",
      "                    compound_0010  ...  compound_1782  compound_1783  \\\n",
      "compound_0001            0.025257  ...       0.193494       0.079586   \n",
      "compound_0002           -0.004132  ...       0.024646       0.218170   \n",
      "compound_0003           -0.034558  ...       0.128955       0.280625   \n",
      "compound_0004           -0.019184  ...       0.177720       0.276556   \n",
      "compound_0005            0.046967  ...       0.041707       0.270999   \n",
      "...                           ...  ...            ...            ...   \n",
      "compound_1787            0.215988  ...       0.084200       0.477451   \n",
      "compound_1788            0.191693  ...       0.215892       0.619945   \n",
      "compound_1789            0.217737  ...       0.600568       0.600064   \n",
      "compound_1790           -0.089170  ...      -0.232101       0.251313   \n",
      "health_status_case       0.080106  ...      -0.164586      -0.019379   \n",
      "\n",
      "                    compound_1784  compound_1785  compound_1786  \\\n",
      "compound_0001           -0.071359      -0.204456       0.037347   \n",
      "compound_0002            0.387511       0.032275       0.459015   \n",
      "compound_0003            0.388184      -0.051592       0.419259   \n",
      "compound_0004            0.446611       0.078227       0.413654   \n",
      "compound_0005            0.463228       0.041787       0.515701   \n",
      "...                           ...            ...            ...   \n",
      "compound_1787            0.646332       0.245367       0.798010   \n",
      "compound_1788            0.698220       0.234053       0.882839   \n",
      "compound_1789            0.534985      -0.060173       0.815141   \n",
      "compound_1790            0.470576       0.195458       0.636481   \n",
      "health_status_case      -0.015007       0.160614       0.005417   \n",
      "\n",
      "                    compound_1787  compound_1788  compound_1789  \\\n",
      "compound_0001           -0.042484      -0.120095       0.077883   \n",
      "compound_0002            0.465870       0.424939       0.429818   \n",
      "compound_0003            0.394920       0.383943       0.498214   \n",
      "compound_0004            0.495689       0.480303       0.500414   \n",
      "compound_0005            0.573863       0.460999       0.518997   \n",
      "...                           ...            ...            ...   \n",
      "compound_1787            1.000000       0.712137       0.647195   \n",
      "compound_1788            0.712137       1.000000       0.704865   \n",
      "compound_1789            0.647195       0.704865       1.000000   \n",
      "compound_1790            0.611457       0.652798       0.426005   \n",
      "health_status_case       0.006853      -0.076151      -0.198984   \n",
      "\n",
      "                    compound_1790  health_status_case  \n",
      "compound_0001           -0.102652            0.048742  \n",
      "compound_0002            0.495085           -0.205328  \n",
      "compound_0003            0.391304           -0.281018  \n",
      "compound_0004            0.386951           -0.237960  \n",
      "compound_0005            0.513177           -0.215671  \n",
      "...                           ...                 ...  \n",
      "compound_1787            0.611457            0.006853  \n",
      "compound_1788            0.652798           -0.076151  \n",
      "compound_1789            0.426005           -0.198984  \n",
      "compound_1790            1.000000           -0.108593  \n",
      "health_status_case      -0.108593            1.000000  \n",
      "\n",
      "[1791 rows x 1791 columns]\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#plt.figure(figsize=(15,15))\n",
    "cor = data_full.corr()\n",
    "#sns.heatmap(cor, annot=True, cmap=plt.cm.Reds)\n",
    "#plt.show()\n",
    "print(cor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e09348c4-3ea8-44b0-8850-916186366e76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "compound_0037         0.343934\n",
       "compound_0056         0.300360\n",
       "compound_0077         0.369706\n",
       "compound_0100         0.379360\n",
       "compound_0107         0.370913\n",
       "compound_0124         0.316097\n",
       "compound_0149         0.335619\n",
       "compound_0308         0.309000\n",
       "compound_0309         0.366633\n",
       "compound_0353         0.339252\n",
       "compound_0374         0.344536\n",
       "compound_0375         0.381615\n",
       "compound_0383         0.325261\n",
       "compound_0390         0.351095\n",
       "compound_0401         0.318854\n",
       "compound_0440         0.362040\n",
       "compound_0470         0.390107\n",
       "compound_0477         0.358594\n",
       "compound_0501         0.357031\n",
       "compound_0570         0.304442\n",
       "compound_0580         0.374898\n",
       "compound_0584         0.409995\n",
       "compound_0585         0.355245\n",
       "compound_0587         0.349872\n",
       "compound_0794         0.307622\n",
       "compound_0797         0.381140\n",
       "compound_0798         0.343702\n",
       "compound_0799         0.374894\n",
       "compound_1248         0.367731\n",
       "compound_1249         0.419453\n",
       "compound_1251         0.339776\n",
       "health_status_case    1.000000\n",
       "Name: health_status_case, dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Correlation with output variable\n",
    "cor_label = abs(cor[\"health_status_case\"])\n",
    "#Selecting highly correlated features\n",
    "relevant_features = cor_label[cor_label>0.3]\n",
    "relevant_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8378175c-4b7e-489b-895b-1a99dd8cc8ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "26b2e1a8-d516-4607-b9f2-24b1c4139ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "featured_data = data_full[['compound_0037','compound_0056', 'compound_0077','compound_0100','compound_0107', 'compound_0124', 'compound_0149', 'compound_0308',        \n",
    "                     'compound_0309','compound_0353', 'compound_0374','compound_0375','compound_0383', 'compound_0390', 'compound_0401', 'compound_0440',         \n",
    "                     'compound_0470','compound_0477', 'compound_0501','compound_0570','compound_0580', 'compound_0584', 'compound_0585', 'compound_0587',         \n",
    "                     'compound_0794','compound_0797', 'compound_0798','compound_0799','compound_1248', 'compound_1249', 'compound_1251','health_status_case']] \n",
    "\n",
    "feat_X = featured_data.iloc[:, :-1]\n",
    "feat_y = featured_data.iloc[:, -1]\n",
    "feat_data_train, feat_data_test, feat_label_train, feat_label_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eecb8680-5fc5-478c-a8f4-cc8ac9d6b78a",
   "metadata": {},
   "source": [
    "## Keras classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3c607c29-0d1a-4bf0-98cf-a53948cefeda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras import ops\n",
    "from keras import layers\n",
    "target_train = pd.get_dummies(feat_label_train)\n",
    "target_test = pd.get_dummies(feat_label_test)\n",
    "\n",
    "inputs = keras.Input(shape = (feat_data_train.shape[1],))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "96a7a580-449b-482d-8c29-3dde210b0017",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_layer = keras.layers.Dense(32, activation = 'relu')(inputs)\n",
    "hidden_layer = keras.layers.Dense(16, activation = 'relu')(hidden_layer)\n",
    "hidden_layer = keras.layers.Dense(8, activation = 'relu')(hidden_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4bbd610e-d8fa-4b62-a765-1a12902c6020",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_layer = keras.layers.Dense(1, activation=\"sigmoid\")(hidden_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c08c1654-e5b5-49f2-a79e-c487bb67b14f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1790</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">57,312</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">136</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1790\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │        \u001b[38;5;34m57,312\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │           \u001b[38;5;34m528\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │           \u001b[38;5;34m136\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m9\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">57,985</span> (226.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m57,985\u001b[0m (226.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">57,985</span> (226.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m57,985\u001b[0m (226.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = keras.Model(inputs=inputs, outputs=output_layer)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a9e5ca83-b903-4857-a42f-71ac74e69012",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a12ec9bb-72dd-414d-9fa2-da30e41f00f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4174 - loss: 8956132.0000 0\n",
      "Epoch 2/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 732us/step - accuracy: 0.4644 - loss: 6476351.0000\n",
      "Epoch 3/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 709us/step - accuracy: 0.4441 - loss: 4263631.5000\n",
      "Epoch 4/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step - accuracy: 0.3789 - loss: 2851200.5000\n",
      "Epoch 5/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 897us/step - accuracy: 0.6834 - loss: 1932719.5000\n",
      "Epoch 6/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 774us/step - accuracy: 0.5888 - loss: 1947468.7500\n",
      "Epoch 7/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 938us/step - accuracy: 0.5025 - loss: 2064196.2500\n",
      "Epoch 8/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - accuracy: 0.6116 - loss: 1237654.2500\n",
      "Epoch 9/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 819us/step - accuracy: 0.5850 - loss: 2831755.0000\n",
      "Epoch 10/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 790us/step - accuracy: 0.6183 - loss: 2197540.7500\n",
      "Epoch 11/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 825us/step - accuracy: 0.6207 - loss: 1524673.3750\n",
      "Epoch 12/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 881us/step - accuracy: 0.6810 - loss: 1171507.5000\n",
      "Epoch 13/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812us/step - accuracy: 0.7881 - loss: 770862.1875\n",
      "Epoch 14/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 790us/step - accuracy: 0.7020 - loss: 797153.9375 \n",
      "Epoch 15/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 787us/step - accuracy: 0.6695 - loss: 772300.5000\n",
      "Epoch 16/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 673us/step - accuracy: 0.7893 - loss: 287124.0312\n",
      "Epoch 17/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 887us/step - accuracy: 0.8524 - loss: 362727.9062\n",
      "Epoch 18/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 795us/step - accuracy: 0.9147 - loss: 72594.4531\n",
      "Epoch 19/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 627us/step - accuracy: 0.8774 - loss: 80704.1875\n",
      "Epoch 20/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 729us/step - accuracy: 0.7687 - loss: 466831.5938\n",
      "Epoch 21/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 844us/step - accuracy: 0.6533 - loss: 2386071.5000\n",
      "Epoch 22/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 723us/step - accuracy: 0.5517 - loss: 1593961.3750\n",
      "Epoch 23/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 761us/step - accuracy: 0.6888 - loss: 997423.2500\n",
      "Epoch 24/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 902us/step - accuracy: 0.4299 - loss: 5649047.0000\n",
      "Epoch 25/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 881us/step - accuracy: 0.6528 - loss: 1243778.0000\n",
      "Epoch 26/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 797us/step - accuracy: 0.6667 - loss: 1917847.1250\n",
      "Epoch 27/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 875us/step - accuracy: 0.7104 - loss: 923690.0000 \n",
      "Epoch 28/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 801us/step - accuracy: 0.7453 - loss: 777951.0625\n",
      "Epoch 29/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 985us/step - accuracy: 0.8159 - loss: 1117979.0000\n",
      "Epoch 30/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - accuracy: 0.8957 - loss: 311259.8438\n",
      "Epoch 31/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 770us/step - accuracy: 0.8869 - loss: 175195.8750\n",
      "Epoch 32/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - accuracy: 0.9008 - loss: 278487.1250\n",
      "Epoch 33/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 837us/step - accuracy: 0.9673 - loss: 92562.2109\n",
      "Epoch 34/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 845us/step - accuracy: 0.7169 - loss: 1336821.1250\n",
      "Epoch 35/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7179 - loss: 2148703.0000  \n",
      "Epoch 36/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 792us/step - accuracy: 0.7072 - loss: 2151181.0000\n",
      "Epoch 37/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step - accuracy: 0.5679 - loss: 2329455.2500\n",
      "Epoch 38/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 873us/step - accuracy: 0.7022 - loss: 707539.6250\n",
      "Epoch 39/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 751us/step - accuracy: 0.7457 - loss: 1133311.5000\n",
      "Epoch 40/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step - accuracy: 0.8488 - loss: 278555.4062\n",
      "Epoch 41/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 891us/step - accuracy: 1.0000 - loss: 0.0123  \n",
      "Epoch 42/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 760us/step - accuracy: 0.9175 - loss: 194825.9375\n",
      "Epoch 43/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 664us/step - accuracy: 1.0000 - loss: 0.0180\n",
      "Epoch 44/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 740us/step - accuracy: 0.8953 - loss: 107899.6562\n",
      "Epoch 45/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 882us/step - accuracy: 0.8881 - loss: 80405.5234 \n",
      "Epoch 46/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 727us/step - accuracy: 1.0000 - loss: 0.0084    \n",
      "Epoch 47/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 733us/step - accuracy: 1.0000 - loss: 0.0294\n",
      "Epoch 48/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 722us/step - accuracy: 1.0000 - loss: 0.0084   \n",
      "Epoch 49/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - accuracy: 1.0000 - loss: 0.0122\n",
      "Epoch 50/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 737us/step - accuracy: 1.0000 - loss: 0.0056    \n",
      "Epoch 51/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0122      \n",
      "Epoch 52/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 901us/step - accuracy: 1.0000 - loss: 0.0084    \n",
      "Epoch 53/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 752us/step - accuracy: 1.0000 - loss: 0.0179 \n",
      "Epoch 54/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0084      \n",
      "Epoch 55/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 922us/step - accuracy: 1.0000 - loss: 0.0293\n",
      "Epoch 56/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 969us/step - accuracy: 1.0000 - loss: 0.0293\n",
      "Epoch 57/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 830us/step - accuracy: 1.0000 - loss: 0.0293\n",
      "Epoch 58/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 842us/step - accuracy: 1.0000 - loss: 0.0122    \n",
      "Epoch 59/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 821us/step - accuracy: 1.0000 - loss: 0.0179 \n",
      "Epoch 60/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 819us/step - accuracy: 1.0000 - loss: 0.0084  \n",
      "Epoch 61/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 880us/step - accuracy: 1.0000 - loss: 0.0084    \n",
      "Epoch 62/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 781us/step - accuracy: 1.0000 - loss: 0.0293\n",
      "Epoch 63/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 817us/step - accuracy: 1.0000 - loss: 0.0293\n",
      "Epoch 64/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 777us/step - accuracy: 1.0000 - loss: 0.0122\n",
      "Epoch 65/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 839us/step - accuracy: 1.0000 - loss: 0.0084    \n",
      "Epoch 66/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 936us/step - accuracy: 1.0000 - loss: 0.0293\n",
      "Epoch 67/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 824us/step - accuracy: 1.0000 - loss: 0.0293\n",
      "Epoch 68/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0293  \n",
      "Epoch 69/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0179  +\n",
      "Epoch 70/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 980us/step - accuracy: 1.0000 - loss: 0.0122    \n",
      "Epoch 71/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 898us/step - accuracy: 1.0000 - loss: 0.0084    \n",
      "Epoch 72/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0084    \n",
      "Epoch 73/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 889us/step - accuracy: 1.0000 - loss: 0.0293\n",
      "Epoch 74/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 802us/step - accuracy: 1.0000 - loss: 0.0084  \n",
      "Epoch 75/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 835us/step - accuracy: 1.0000 - loss: 0.0179\n",
      "Epoch 76/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 752us/step - accuracy: 1.0000 - loss: 0.0084    \n",
      "Epoch 77/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 772us/step - accuracy: 1.0000 - loss: 0.0293\n",
      "Epoch 78/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 893us/step - accuracy: 1.0000 - loss: 0.0293\n",
      "Epoch 79/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 674us/step - accuracy: 1.0000 - loss: 0.0122    \n",
      "Epoch 80/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 706us/step - accuracy: 1.0000 - loss: 0.0084    \n",
      "Epoch 81/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 678us/step - accuracy: 1.0000 - loss: 0.0292\n",
      "Epoch 82/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 691us/step - accuracy: 1.0000 - loss: 0.0084    \n",
      "Epoch 83/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 719us/step - accuracy: 1.0000 - loss: 0.0122    \n",
      "Epoch 84/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 781us/step - accuracy: 1.0000 - loss: 0.0055    \n",
      "Epoch 85/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 718us/step - accuracy: 1.0000 - loss: 0.0292\n",
      "Epoch 86/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 843us/step - accuracy: 1.0000 - loss: 0.0122    \n",
      "Epoch 87/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 743us/step - accuracy: 1.0000 - loss: 0.0084    \n",
      "Epoch 88/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 745us/step - accuracy: 1.0000 - loss: 0.0292\n",
      "Epoch 89/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 724us/step - accuracy: 1.0000 - loss: 0.0122    \n",
      "Epoch 90/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 712us/step - accuracy: 1.0000 - loss: 0.0121    \n",
      "Epoch 91/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 692us/step - accuracy: 1.0000 - loss: 0.0292\n",
      "Epoch 92/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 661us/step - accuracy: 1.0000 - loss: 0.0121    \n",
      "Epoch 93/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 725us/step - accuracy: 1.0000 - loss: 0.0121    \n",
      "Epoch 94/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 706us/step - accuracy: 1.0000 - loss: 0.0178\n",
      "Epoch 95/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 708us/step - accuracy: 1.0000 - loss: 0.0084    \n",
      "Epoch 96/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 639us/step - accuracy: 1.0000 - loss: 0.0084    \n",
      "Epoch 97/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 790us/step - accuracy: 1.0000 - loss: 0.0121    \n",
      "Epoch 98/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step - accuracy: 1.0000 - loss: 0.0291\n",
      "Epoch 99/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 729us/step - accuracy: 1.0000 - loss: 0.0084    \n",
      "Epoch 100/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 844us/step - accuracy: 1.0000 - loss: 0.0121  \n",
      "Epoch 101/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 849us/step - accuracy: 1.0000 - loss: 0.0291\n",
      "Epoch 102/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 749us/step - accuracy: 1.0000 - loss: 0.0121    \n",
      "Epoch 103/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 828us/step - accuracy: 1.0000 - loss: 0.0291\n",
      "Epoch 104/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 689us/step - accuracy: 1.0000 - loss: 0.0178\n",
      "Epoch 105/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step - accuracy: 1.0000 - loss: 0.0121  \n",
      "Epoch 106/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - accuracy: 1.0000 - loss: 0.0121e+\n",
      "Epoch 107/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 691us/step - accuracy: 1.0000 - loss: 0.0121    \n",
      "Epoch 108/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 705us/step - accuracy: 1.0000 - loss: 0.0178 \n",
      "Epoch 109/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 755us/step - accuracy: 1.0000 - loss: 0.0121    \n",
      "Epoch 110/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 686us/step - accuracy: 1.0000 - loss: 0.0055    \n",
      "Epoch 111/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 864us/step - accuracy: 1.0000 - loss: 0.0291\n",
      "Epoch 112/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 709us/step - accuracy: 1.0000 - loss: 0.0177\n",
      "Epoch 113/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 738us/step - accuracy: 1.0000 - loss: 0.0177\n",
      "Epoch 114/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 699us/step - accuracy: 1.0000 - loss: 0.0083    \n",
      "Epoch 115/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 712us/step - accuracy: 1.0000 - loss: 0.0177\n",
      "Epoch 116/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 698us/step - accuracy: 1.0000 - loss: 0.0290\n",
      "Epoch 117/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 793us/step - accuracy: 1.0000 - loss: 0.0290\n",
      "Epoch 118/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 728us/step - accuracy: 1.0000 - loss: 0.0083    \n",
      "Epoch 119/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 848us/step - accuracy: 1.0000 - loss: 0.0121  \n",
      "Epoch 120/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 759us/step - accuracy: 1.0000 - loss: 0.0083    \n",
      "Epoch 121/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 696us/step - accuracy: 1.0000 - loss: 0.0121    \n",
      "Epoch 122/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 774us/step - accuracy: 1.0000 - loss: 0.0177\n",
      "Epoch 123/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 880us/step - accuracy: 1.0000 - loss: 0.0083  \n",
      "Epoch 124/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 771us/step - accuracy: 1.0000 - loss: 0.0083    \n",
      "Epoch 125/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 732us/step - accuracy: 1.0000 - loss: 0.0289\n",
      "Epoch 126/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - accuracy: 1.0000 - loss: 0.0121    \n",
      "Epoch 127/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 777us/step - accuracy: 1.0000 - loss: 0.0083    \n",
      "Epoch 128/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 707us/step - accuracy: 1.0000 - loss: 0.0289\n",
      "Epoch 129/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 957us/step - accuracy: 1.0000 - loss: 0.0289\n",
      "Epoch 130/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step - accuracy: 1.0000 - loss: 0.0289\n",
      "Epoch 131/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0177   \n",
      "Epoch 132/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0289  \n",
      "Epoch 133/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 734us/step - accuracy: 1.0000 - loss: 0.0177+\n",
      "Epoch 134/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 795us/step - accuracy: 1.0000 - loss: 0.0289\n",
      "Epoch 135/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 745us/step - accuracy: 1.0000 - loss: 0.0289\n",
      "Epoch 136/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 668us/step - accuracy: 1.0000 - loss: 0.0083    \n",
      "Epoch 137/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 735us/step - accuracy: 1.0000 - loss: 0.0176\n",
      "Epoch 138/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 914us/step - accuracy: 1.0000 - loss: 0.0176\n",
      "Epoch 139/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 754us/step - accuracy: 1.0000 - loss: 0.0120    \n",
      "Epoch 140/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step - accuracy: 1.0000 - loss: 0.0083    \n",
      "Epoch 141/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 702us/step - accuracy: 1.0000 - loss: 0.0120    \n",
      "Epoch 142/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 745us/step - accuracy: 1.0000 - loss: 0.0083    \n",
      "Epoch 143/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 766us/step - accuracy: 1.0000 - loss: 0.0120\n",
      "Epoch 144/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 927us/step - accuracy: 1.0000 - loss: 0.0176\n",
      "Epoch 145/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 865us/step - accuracy: 1.0000 - loss: 0.0120  \n",
      "Epoch 146/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0083   \n",
      "Epoch 147/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0083    \n",
      "Epoch 148/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 831us/step - accuracy: 1.0000 - loss: 0.0288\n",
      "Epoch 149/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 918us/step - accuracy: 1.0000 - loss: 0.0176\n",
      "Epoch 150/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - accuracy: 1.0000 - loss: 0.0176\n",
      "Epoch 151/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 821us/step - accuracy: 1.0000 - loss: 0.0120    \n",
      "Epoch 152/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 757us/step - accuracy: 1.0000 - loss: 0.0288\n",
      "Epoch 153/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 821us/step - accuracy: 1.0000 - loss: 0.0083    \n",
      "Epoch 154/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 739us/step - accuracy: 1.0000 - loss: 0.0083    \n",
      "Epoch 155/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 733us/step - accuracy: 1.0000 - loss: 0.0288\n",
      "Epoch 156/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 844us/step - accuracy: 1.0000 - loss: 0.0082    \n",
      "Epoch 157/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 745us/step - accuracy: 1.0000 - loss: 0.0176\n",
      "Epoch 158/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 694us/step - accuracy: 1.0000 - loss: 0.0176  \n",
      "Epoch 159/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 834us/step - accuracy: 1.0000 - loss: 0.0287\n",
      "Epoch 160/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 784us/step - accuracy: 1.0000 - loss: 0.0175\n",
      "Epoch 161/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 994us/step - accuracy: 1.0000 - loss: 0.0120  \n",
      "Epoch 162/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 706us/step - accuracy: 1.0000 - loss: 0.0082  \n",
      "Epoch 163/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 692us/step - accuracy: 1.0000 - loss: 0.0175  \n",
      "Epoch 164/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 765us/step - accuracy: 1.0000 - loss: 0.0082    \n",
      "Epoch 165/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0054     \n",
      "Epoch 166/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 884us/step - accuracy: 1.0000 - loss: 0.0175 \n",
      "Epoch 167/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 885us/step - accuracy: 1.0000 - loss: 0.0286\n",
      "Epoch 168/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step - accuracy: 1.0000 - loss: 0.0119  \n",
      "Epoch 169/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 854us/step - accuracy: 1.0000 - loss: 0.0082    \n",
      "Epoch 170/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 746us/step - accuracy: 1.0000 - loss: 0.0286\n",
      "Epoch 171/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 714us/step - accuracy: 1.0000 - loss: 0.0175\n",
      "Epoch 172/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 766us/step - accuracy: 1.0000 - loss: 0.0175\n",
      "Epoch 173/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 857us/step - accuracy: 1.0000 - loss: 0.0119  \n",
      "Epoch 174/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step - accuracy: 1.0000 - loss: 0.0119    \n",
      "Epoch 175/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 752us/step - accuracy: 1.0000 - loss: 0.0082    \n",
      "Epoch 176/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 871us/step - accuracy: 1.0000 - loss: 0.0082    \n",
      "Epoch 177/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812us/step - accuracy: 1.0000 - loss: 0.0119    \n",
      "Epoch 178/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 773us/step - accuracy: 1.0000 - loss: 0.0285\n",
      "Epoch 179/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 817us/step - accuracy: 1.0000 - loss: 0.0285\n",
      "Epoch 180/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 831us/step - accuracy: 1.0000 - loss: 0.0119    \n",
      "Epoch 181/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803us/step - accuracy: 1.0000 - loss: 0.0174\n",
      "Epoch 182/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 736us/step - accuracy: 1.0000 - loss: 0.0174\n",
      "Epoch 183/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 668us/step - accuracy: 1.0000 - loss: 0.0082    \n",
      "Epoch 184/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step - accuracy: 1.0000 - loss: 0.0285\n",
      "Epoch 185/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 750us/step - accuracy: 1.0000 - loss: 0.0119    \n",
      "Epoch 186/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 832us/step - accuracy: 1.0000 - loss: 0.0285\n",
      "Epoch 187/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step - accuracy: 1.0000 - loss: 0.0119  \n",
      "Epoch 188/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 837us/step - accuracy: 1.0000 - loss: 0.0119  \n",
      "Epoch 189/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step - accuracy: 1.0000 - loss: 0.0285\n",
      "Epoch 190/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 730us/step - accuracy: 1.0000 - loss: 0.0174\n",
      "Epoch 191/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 772us/step - accuracy: 1.0000 - loss: 0.0118  \n",
      "Epoch 192/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 843us/step - accuracy: 1.0000 - loss: 0.0118\n",
      "Epoch 193/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 926us/step - accuracy: 1.0000 - loss: 0.0284\n",
      "Epoch 194/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 799us/step - accuracy: 1.0000 - loss: 0.0174\n",
      "Epoch 195/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 713us/step - accuracy: 1.0000 - loss: 0.0118  \n",
      "Epoch 196/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 761us/step - accuracy: 1.0000 - loss: 0.0118    \n",
      "Epoch 197/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 731us/step - accuracy: 1.0000 - loss: 0.0081    \n",
      "Epoch 198/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 725us/step - accuracy: 1.0000 - loss: 0.0284\n",
      "Epoch 199/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 739us/step - accuracy: 1.0000 - loss: 0.0118    \n",
      "Epoch 200/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 908us/step - accuracy: 1.0000 - loss: 0.0118  \n",
      "Epoch 201/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 858us/step - accuracy: 1.0000 - loss: 0.0284\n",
      "Epoch 202/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0173  \n",
      "Epoch 203/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 876us/step - accuracy: 1.0000 - loss: 0.0284\n",
      "Epoch 204/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 770us/step - accuracy: 1.0000 - loss: 0.0173\n",
      "Epoch 205/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 786us/step - accuracy: 1.0000 - loss: 0.0283\n",
      "Epoch 206/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 758us/step - accuracy: 1.0000 - loss: 0.0118\n",
      "Epoch 207/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 791us/step - accuracy: 1.0000 - loss: 0.0118  \n",
      "Epoch 208/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 730us/step - accuracy: 1.0000 - loss: 0.0081    \n",
      "Epoch 209/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 879us/step - accuracy: 1.0000 - loss: 0.0173\n",
      "Epoch 210/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 769us/step - accuracy: 1.0000 - loss: 0.0283\n",
      "Epoch 211/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 721us/step - accuracy: 1.0000 - loss: 0.0081    \n",
      "Epoch 212/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 826us/step - accuracy: 1.0000 - loss: 0.0283\n",
      "Epoch 213/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 841us/step - accuracy: 1.0000 - loss: 0.0173\n",
      "Epoch 214/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 769us/step - accuracy: 1.0000 - loss: 0.0081    \n",
      "Epoch 215/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 783us/step - accuracy: 1.0000 - loss: 0.0283\n",
      "Epoch 216/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 859us/step - accuracy: 1.0000 - loss: 0.0081  \n",
      "Epoch 217/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 853us/step - accuracy: 1.0000 - loss: 0.0173\n",
      "Epoch 218/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 742us/step - accuracy: 1.0000 - loss: 0.0081    \n",
      "Epoch 219/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 820us/step - accuracy: 1.0000 - loss: 0.0118  \n",
      "Epoch 220/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0172  \n",
      "Epoch 221/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0054    \n",
      "Epoch 222/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827us/step - accuracy: 1.0000 - loss: 0.0081    \n",
      "Epoch 223/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 797us/step - accuracy: 1.0000 - loss: 0.0282\n",
      "Epoch 224/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803us/step - accuracy: 1.0000 - loss: 0.0281\n",
      "Epoch 225/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 817us/step - accuracy: 1.0000 - loss: 0.0281\n",
      "Epoch 226/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 763us/step - accuracy: 1.0000 - loss: 0.0053    \n",
      "Epoch 227/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 718us/step - accuracy: 1.0000 - loss: 0.0081    \n",
      "Epoch 228/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 681us/step - accuracy: 1.0000 - loss: 0.0117    \n",
      "Epoch 229/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 765us/step - accuracy: 1.0000 - loss: 0.0117    \n",
      "Epoch 230/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 750us/step - accuracy: 1.0000 - loss: 0.0171\n",
      "Epoch 231/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 787us/step - accuracy: 1.0000 - loss: 0.0080    \n",
      "Epoch 232/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 790us/step - accuracy: 1.0000 - loss: 0.0117e+\n",
      "Epoch 233/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 822us/step - accuracy: 1.0000 - loss: 0.0080    \n",
      "Epoch 234/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 757us/step - accuracy: 1.0000 - loss: 0.0080    \n",
      "Epoch 235/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 763us/step - accuracy: 1.0000 - loss: 0.0080    \n",
      "Epoch 236/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 928us/step - accuracy: 1.0000 - loss: 0.0280\n",
      "Epoch 237/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 762us/step - accuracy: 1.0000 - loss: 0.0116    \n",
      "Epoch 238/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 844us/step - accuracy: 1.0000 - loss: 0.0171\n",
      "Epoch 239/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 727us/step - accuracy: 1.0000 - loss: 0.0080    \n",
      "Epoch 240/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 778us/step - accuracy: 1.0000 - loss: 0.0279\n",
      "Epoch 241/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 796us/step - accuracy: 1.0000 - loss: 0.0279\n",
      "Epoch 242/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 750us/step - accuracy: 1.0000 - loss: 0.0080    \n",
      "Epoch 243/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 844us/step - accuracy: 1.0000 - loss: 0.0170\n",
      "Epoch 244/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 815us/step - accuracy: 1.0000 - loss: 0.0116    \n",
      "Epoch 245/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 801us/step - accuracy: 1.0000 - loss: 0.0080  \n",
      "Epoch 246/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 762us/step - accuracy: 1.0000 - loss: 0.0116    \n",
      "Epoch 247/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 830us/step - accuracy: 1.0000 - loss: 0.0279\n",
      "Epoch 248/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 762us/step - accuracy: 1.0000 - loss: 0.0278\n",
      "Epoch 249/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 798us/step - accuracy: 1.0000 - loss: 0.0170\n",
      "Epoch 250/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0278  \n",
      "Epoch 251/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 750us/step - accuracy: 1.0000 - loss: 0.0053    \n",
      "Epoch 252/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 739us/step - accuracy: 1.0000 - loss: 0.0278\n",
      "Epoch 253/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812us/step - accuracy: 1.0000 - loss: 0.0080    \n",
      "Epoch 254/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 743us/step - accuracy: 1.0000 - loss: 0.0080    \n",
      "Epoch 255/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 752us/step - accuracy: 1.0000 - loss: 0.0169\n",
      "Epoch 256/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 783us/step - accuracy: 1.0000 - loss: 0.0053    \n",
      "Epoch 257/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - accuracy: 1.0000 - loss: 0.0277\n",
      "Epoch 258/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 772us/step - accuracy: 1.0000 - loss: 0.0115\n",
      "Epoch 259/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 784us/step - accuracy: 1.0000 - loss: 0.0079    \n",
      "Epoch 260/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 769us/step - accuracy: 1.0000 - loss: 0.0169\n",
      "Epoch 261/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step - accuracy: 1.0000 - loss: 0.0276\n",
      "Epoch 262/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - accuracy: 1.0000 - loss: 0.0169\n",
      "Epoch 263/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 738us/step - accuracy: 1.0000 - loss: 0.0079    \n",
      "Epoch 264/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 674us/step - accuracy: 1.0000 - loss: 0.0276\n",
      "Epoch 265/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 783us/step - accuracy: 1.0000 - loss: 0.0168\n",
      "Epoch 266/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 828us/step - accuracy: 1.0000 - loss: 0.0079    \n",
      "Epoch 267/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 717us/step - accuracy: 1.0000 - loss: 0.0168\n",
      "Epoch 268/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 767us/step - accuracy: 1.0000 - loss: 0.0275\n",
      "Epoch 269/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 715us/step - accuracy: 1.0000 - loss: 0.0168\n",
      "Epoch 270/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 686us/step - accuracy: 1.0000 - loss: 0.0168\n",
      "Epoch 271/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 737us/step - accuracy: 1.0000 - loss: 0.0168\n",
      "Epoch 272/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 773us/step - accuracy: 1.0000 - loss: 0.0125    \n",
      "Epoch 273/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 742us/step - accuracy: 1.0000 - loss: 0.0079    \n",
      "Epoch 274/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step - accuracy: 1.0000 - loss: 0.0079    \n",
      "Epoch 275/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 893us/step - accuracy: 1.0000 - loss: 0.0168\n",
      "Epoch 276/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 798us/step - accuracy: 1.0000 - loss: 0.0168\n",
      "Epoch 277/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 691us/step - accuracy: 1.0000 - loss: 0.0079  \n",
      "Epoch 278/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 727us/step - accuracy: 1.0000 - loss: 0.0168\n",
      "Epoch 279/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 681us/step - accuracy: 1.0000 - loss: 0.0168  \n",
      "Epoch 280/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 693us/step - accuracy: 1.0000 - loss: 0.0114    \n",
      "Epoch 281/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 702us/step - accuracy: 1.0000 - loss: 0.0167\n",
      "Epoch 282/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 750us/step - accuracy: 1.0000 - loss: 0.0167\n",
      "Epoch 283/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 698us/step - accuracy: 1.0000 - loss: 0.0079    \n",
      "Epoch 284/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 735us/step - accuracy: 1.0000 - loss: 0.0167\n",
      "Epoch 285/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 707us/step - accuracy: 1.0000 - loss: 0.0274\n",
      "Epoch 286/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 756us/step - accuracy: 1.0000 - loss: 0.0078    \n",
      "Epoch 287/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 778us/step - accuracy: 1.0000 - loss: 0.0078    \n",
      "Epoch 288/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 779us/step - accuracy: 1.0000 - loss: 0.0078    \n",
      "Epoch 289/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0167   \n",
      "Epoch 290/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0114   \n",
      "Epoch 291/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - accuracy: 1.0000 - loss: 0.0078    \n",
      "Epoch 292/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 813us/step - accuracy: 1.0000 - loss: 0.0114  \n",
      "Epoch 293/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 794us/step - accuracy: 1.0000 - loss: 0.0114  \n",
      "Epoch 294/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 770us/step - accuracy: 1.0000 - loss: 0.0167\n",
      "Epoch 295/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 748us/step - accuracy: 1.0000 - loss: 0.0273\n",
      "Epoch 296/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 787us/step - accuracy: 1.0000 - loss: 0.0114    \n",
      "Epoch 297/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 820us/step - accuracy: 1.0000 - loss: 0.0167\n",
      "Epoch 298/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step - accuracy: 1.0000 - loss: 0.0272\n",
      "Epoch 299/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 816us/step - accuracy: 1.0000 - loss: 0.0272\n",
      "Epoch 300/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 876us/step - accuracy: 1.0000 - loss: 0.0078    \n"
     ]
    }
   ],
   "source": [
    "history = model.fit(feat_data_train, feat_label_train, batch_size= 10, shuffle= True, epochs=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "79cf5ba3-869f-4f8b-bb41-abdc11d36134",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.lineplot(x=history.epoch, y=history.history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8739be67-483f-442b-870a-17cec07bf0eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.lineplot(x=history.epoch, y=history.history['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d458c1bd-36fe-470b-b05d-703e67b535c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0\n",
       "0   1.0\n",
       "1   0.0\n",
       "2   1.0\n",
       "3   0.0\n",
       "4   0.0\n",
       "5   0.0\n",
       "6   0.0\n",
       "7   1.0\n",
       "8   1.0\n",
       "9   1.0\n",
       "10  1.0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_pred = model.predict(feat_data_test)\n",
    "prediction = pd.DataFrame(label_pred)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "21ecd209-a4f2-4c99-8802-57d8b74ac1f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.5455 - loss: 254834.1406\n",
      "Test Loss: 254834.140625\n",
      "Test accuracy: 0.5454545617103577\n"
     ]
    }
   ],
   "source": [
    "test_scores = model.evaluate(feat_data_test, feat_label_test)\n",
    "print(\"Test Loss:\", test_scores[0])\n",
    "print(\"Test accuracy:\", test_scores[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf442d4-9e25-445e-bced-1c5eaa3311d8",
   "metadata": {},
   "source": [
    "# CHAT GPT CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "23df3736-42b0-43c2-be9b-725794d2a635",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/borja/anaconda3/envs/Kaggle/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.6456 - auc: 0.6743 - loss: 61340792.0000 - val_accuracy: 0.4444 - val_auc: 0.5000 - val_loss: 18538410.0000\n",
      "Epoch 2/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6305 - auc: 0.6295 - loss: 39909420.0000 - val_accuracy: 0.4444 - val_auc: 0.5000 - val_loss: 23451720.0000\n",
      "Epoch 3/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4655 - auc: 0.4438 - loss: 30538900.0000 - val_accuracy: 0.4444 - val_auc: 0.5000 - val_loss: 20362048.0000\n",
      "Epoch 4/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5916 - auc: 0.5962 - loss: 35044248.0000 - val_accuracy: 0.4444 - val_auc: 0.5000 - val_loss: 5652266.0000\n",
      "Epoch 5/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3495 - auc: 0.3833 - loss: 34387792.0000 - val_accuracy: 0.3333 - val_auc: 0.3750 - val_loss: 3627327.7500\n",
      "Epoch 6/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6750 - auc: 0.6605 - loss: 7884403.0000 - val_accuracy: 0.4444 - val_auc: 0.5000 - val_loss: 4675931.0000\n",
      "Epoch 7/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6751 - auc: 0.6383 - loss: 7379849.5000 - val_accuracy: 0.5556 - val_auc: 0.6000 - val_loss: 4902619.5000\n",
      "Epoch 8/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5621 - auc: 0.4354 - loss: 8684576.0000 - val_accuracy: 0.4444 - val_auc: 0.4750 - val_loss: 3594691.5000\n",
      "Epoch 9/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6619 - auc: 0.5553 - loss: 10012762.0000 - val_accuracy: 0.5556 - val_auc: 0.6000 - val_loss: 3272463.7500\n",
      "Epoch 10/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4853 - auc: 0.4078 - loss: 10001939.0000 - val_accuracy: 0.4444 - val_auc: 0.5000 - val_loss: 4315322.5000\n",
      "Epoch 11/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6021 - auc: 0.5363 - loss: 4614833.0000 - val_accuracy: 0.4444 - val_auc: 0.5000 - val_loss: 4607823.5000\n",
      "Epoch 12/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6499 - auc: 0.5591 - loss: 652388.3750 - val_accuracy: 0.4444 - val_auc: 0.5000 - val_loss: 4437039.5000\n",
      "Epoch 13/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4395 - auc: 0.3104 - loss: 4192128.7500 - val_accuracy: 0.5556 - val_auc: 0.6000 - val_loss: 4092905.0000\n",
      "Epoch 14/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6798 - auc: 0.4495 - loss: 1503443.7500 - val_accuracy: 0.5556 - val_auc: 0.4000 - val_loss: 3502036.0000\n",
      "Test Loss: 0.9360, Test Accuracy: 0.4545, Test AUC: 0.6667\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x1305725c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "Confusion Matrix:\n",
      "[[2 0]\n",
      " [6 3]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     control       0.25      1.00      0.40         2\n",
      "        case       1.00      0.33      0.50         9\n",
      "\n",
      "    accuracy                           0.45        11\n",
      "   macro avg       0.62      0.67      0.45        11\n",
      "weighted avg       0.86      0.45      0.48        11\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Define the model\n",
    "model = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(feat_data_train.shape[1],)),  # Feature extraction layer\n",
    "    Dropout(0.5),\n",
    "    Dense(32, activation='relu', kernel_regularizer=l2(0.001)),  # Additional layer for further feature extraction\n",
    "    Dropout(0.5),\n",
    "    Dense(32, activation='relu', kernel_regularizer=l2(0.001)),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')  # Output layer for binary classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy', tf.keras.metrics.AUC(name='auc')])\n",
    "\n",
    "# Add early stopping to prevent overfitting\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    feat_data_train, feat_label_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=50,\n",
    "    batch_size=5,\n",
    "    callbacks=[early_stopping],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy, test_auc = model.evaluate(data_test, feat_label_test, verbose=0)\n",
    "print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}, Test AUC: {test_auc:.4f}\")\n",
    "\n",
    "# Generate predictions\n",
    "y_pred = (model.predict(data_test) > 0.5).astype(\"int32\")\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(feat_label_test, y_pred))\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(feat_label_test, y_pred, target_names=[\"control\", \"case\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "11382f17-f5e3-49d2-ad53-40e07295a114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4545 - auc: 0.6667 - loss: 0.9360\n",
      "Test Loss: 0.9360226988792419\n",
      "Test accuracy: 0.4545454680919647\n"
     ]
    }
   ],
   "source": [
    "test_scores = model.evaluate(data_test, feat_label_test)\n",
    "print(\"Test Loss:\", test_scores[0])\n",
    "print(\"Test accuracy:\", test_scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0176728f-8274-4988-85d6-fedd869a79cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
